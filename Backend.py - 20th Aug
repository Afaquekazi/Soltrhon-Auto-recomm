from flask import Flask, request, jsonify
from flask_cors import CORS
from openai import OpenAI
import logging
import os
import json
import requests  # ADD THIS LINE
import hashlib
import base64
import json
import datetime


# NEW FIREBASE IMPORTS
import firebase_admin
from firebase_admin import credentials, firestore, auth
import jwt
import datetime
from functools import wraps

app = Flask(__name__)

# FIXED: Single CORS configuration (no duplicates)
CORS(app,
     origins=['*'],
     allow_headers=['Content-Type', 'Authorization'],
     methods=['GET', 'POST', 'OPTIONS'],
     supports_credentials=False)

# REMOVED: @app.after_request and @app.before_request functions (were causing duplicate headers)

logging.basicConfig(level=logging.INFO)
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY', '')
client = OpenAI(api_key=OPENAI_API_KEY)

# MAILGUN CONFIGURATION - ADD THIS ENTIRE SECTION
MAILGUN_API_KEY = os.getenv('MAILGUN_API_KEY', '')
MAILGUN_DOMAIN = os.getenv('MAILGUN_DOMAIN', 'mg.solthron.com')
MAILGUN_BASE_URL = os.getenv('MAILGUN_BASE_URL', 'https://api.mailgun.net/v3')
FRONTEND_BASE_URL = os.getenv('FRONTEND_BASE_URL', 'https://solthron.com')
VERIFICATION_BASE_URL = os.getenv('VERIFICATION_BASE_URL', 'https://afaque.pythonanywhere.com')

print(f"üîë Mailgun API key loaded: {'‚úÖ' if MAILGUN_API_KEY else '‚ùå'}")
print(f"üåê Mailgun domain: {MAILGUN_DOMAIN}")

# FIREBASE ADMIN SDK INITIALIZATION
try:
    # Initialize Firebase Admin SDK
    cred = credentials.Certificate('/home/Afaque/mysite/firebase-service-account.json')
    firebase_admin.initialize_app(cred)
    db = firestore.client()
    FIREBASE_ENABLED = True
    print("‚úÖ Firebase Admin SDK initialized successfully")

except Exception as e:
    print(f"‚ùå Firebase initialization failed: {e}")
    FIREBASE_ENABLED = False

# CREDIT MAPPING FUNCTION (matches your extension logic exactly)
def get_feature_credits(mode):
    """Map features to credit costs - matches extension logic exactly"""

    # Text Processing: 6 credits
    text_processing_modes = [
        'reframe_casual', 'reframe_technical', 'reframe_professional',
        'reframe_eli5', 'reframe_short', 'reframe_long'
    ]

    # Convert Prompts: 8 credits
    convert_prompt_modes = [
        'convert_concise', 'convert_balanced', 'convert_detailed'
    ]

    # Persona AI Generator: 10 credits
    persona_modes = ['persona_generator']

    # Image Processing: 12 credits
    image_modes = ['image_prompt', 'image_caption']

    # Explain: 5 credits
    explain_modes = ['explain_meaning', 'explain_story', 'explain_eli5']

    # AI Assistant: 15 credits
    ai_assistant_modes = ['smart_followups', 'smart_actions', 'smart_enhancements']

    # Auto Suggestion: 3 credits (per analysis)
    auto_suggestion_modes = ['auto_suggestion']

    # Magic pill enhancement: 10 credits
    magic_pill_modes = ['magic_pill_enhance']

    # Free Features: 0 credits
    free_modes = ['save_note', 'save_prompt', 'save_persona']

    # Determine credit cost based on mode
    if mode in text_processing_modes:
        return 6
    elif mode in convert_prompt_modes:
        return 8
    elif mode in persona_modes:
        return 10
    elif mode in image_modes:
        return 12
    elif mode in explain_modes:
        return 5
    elif mode in ai_assistant_modes:
        return 15
    elif mode in auto_suggestion_modes:
        return 3
    elif mode in magic_pill_modes:
        return 10
    elif mode in free_modes:
        return 0
    else:
        return 6  # Default fallback

# AUTHENTICATION HELPER FUNCTIONS
def verify_auth_token(token):
    """Verify JWT token and return user info"""
    if not FIREBASE_ENABLED:
        return None

    try:
        # Decode JWT token
        payload = jwt.decode(token, options={"verify_signature": False})
        user_id = payload.get('uid') or payload.get('user_id')

        if not user_id:
            return None

        # Get user from Firebase
        user_ref = db.collection('users').document(user_id)
        user_doc = user_ref.get()

        if user_doc.exists:
            return {
                'uid': user_id,
                'data': user_doc.to_dict()
            }
        return None

    except Exception as e:
        print(f"Token verification failed: {e}")
        return None

def check_and_deduct_credits(user_uid, feature_mode):
    """Check if user has enough credits and deduct them"""
    if not FIREBASE_ENABLED:
        return {'success': True, 'message': 'Firebase disabled - allowing free usage'}

    try:
        required_credits = get_feature_credits(feature_mode)

        # Free features don't need credit checks
        if required_credits == 0:
            return {'success': True, 'credits_used': 0}

        # Get user document
        user_ref = db.collection('users').document(user_uid)

        # Use Firestore transaction for atomic credit deduction
        @firestore.transactional
        def update_credits(transaction):
            user_doc = user_ref.get(transaction=transaction)

            if not user_doc.exists:
                return {'success': False, 'message': 'User not found'}

            user_data = user_doc.to_dict()
            current_credits = user_data.get('credits', 0)

            if current_credits < required_credits:
                return {
                    'success': False,
                    'message': f'Insufficient credits. Need {required_credits}, have {current_credits}',
                    'current_credits': current_credits
                }

            # Deduct credits
            new_credits = current_credits - required_credits
            transaction.update(user_ref, {
                'credits': new_credits,
                'lastUpdated': firestore.SERVER_TIMESTAMP
            })

            # Log transaction
            transaction_ref = db.collection('transactions').document()
            transaction.set(transaction_ref, {
                'userId': user_uid,
                'feature': feature_mode,
                'creditsUsed': required_credits,
                'timestamp': firestore.SERVER_TIMESTAMP,
                'creditsRemaining': new_credits
            })

            return {
                'success': True,
                'credits_used': required_credits,
                'remaining': new_credits
            }

        # Execute transaction
        transaction = db.transaction()
        result = update_credits(transaction)
        return result

    except Exception as e:
        print(f"Credit deduction error: {e}")
        return {'success': False, 'message': str(e)}

def optional_credit_check(feature_mode):
    """Optional credit check that doesn't break existing functionality"""
    try:
        # Check if user sent auth token
        auth_header = request.headers.get('Authorization')

        # If no auth token, allow free usage (backwards compatibility)
        if not auth_header or not auth_header.startswith('Bearer '):
            return {'success': False, 'message': 'Authentication required'}

        # If auth token provided, verify and check credits
        token = auth_header[7:]
        user_info = verify_auth_token(token)

        if not user_info:
            return {'success': True, 'message': 'Invalid token - allowing free usage'}

        # Check and deduct credits
        result = check_and_deduct_credits(user_info['uid'], feature_mode)
        return result

    except Exception as e:
        # On any error, allow free usage (safety fallback)
        print(f"Credit check error: {e}")
        return {'success': True, 'message': 'Credit check failed - allowing free usage'}


# ============================================
# MAILGUN EMAIL FUNCTIONS - ADD THIS SECTION
# ============================================

def generate_verification_token_v2(email):
    """Generate a verification token with embedded expiration - RELIABLE VERSION"""
    try:
        # Create expiration time (24 hours from now)
        expiration = datetime.datetime.utcnow() + datetime.timedelta(hours=24)

        # Create token data
        token_data = {
            'email': email,
            'expires': expiration.isoformat(),
            'created': datetime.datetime.utcnow().isoformat(),
            'secret': MAILGUN_API_KEY[:16] if MAILGUN_API_KEY else "fallback_key"
        }

        # Encode to JSON then base64
        json_str = json.dumps(token_data)
        token_bytes = json_str.encode('utf-8')
        token_b64 = base64.urlsafe_b64encode(token_bytes).decode('utf-8')

        # Create hash for verification
        final_string = f"{token_b64}:{MAILGUN_API_KEY}"
        token_hash = hashlib.sha256(final_string.encode()).hexdigest()[:16]

        # Combine base64 data with hash
        final_token = f"{token_b64}.{token_hash}"

        print(f"üîß DEBUG: Token generated successfully for {email}")
        return final_token

    except Exception as e:
        print(f"‚ùå Token generation failed: {e}")
        return None

def verify_token_v2(email, token):
    """Verify token with embedded expiration - RELIABLE VERSION"""
    try:
        if not MAILGUN_API_KEY:
            print(f"‚ùå Token verification failed: No API key")
            return False

        if not token or '.' not in token:
            print(f"‚ùå Invalid token format: {token}")
            return False

        # Split token into data and hash parts
        try:
            token_b64, token_hash = token.rsplit('.', 1)
        except ValueError:
            print(f"‚ùå Could not split token")
            return False

        # Verify hash first
        expected_hash = hashlib.sha256(f"{token_b64}:{MAILGUN_API_KEY}".encode()).hexdigest()[:16]
        if expected_hash != token_hash:
            print(f"‚ùå Token hash verification failed")
            return False

        # Decode token data
        try:
            token_bytes = base64.urlsafe_b64decode(token_b64.encode('utf-8'))
            token_json = token_bytes.decode('utf-8')
            token_data = json.loads(token_json)
        except Exception as decode_error:
            print(f"‚ùå Token decode error: {decode_error}")
            return False

        # Verify email matches
        if token_data.get('email') != email:
            print(f"‚ùå Email mismatch in token")
            return False

        # Check expiration
        try:
            expiration = datetime.datetime.fromisoformat(token_data['expires'])
            current_time = datetime.datetime.utcnow()

            if current_time > expiration:
                print(f"‚ùå Token has expired")
                return False

            print(f"‚úÖ Token verified successfully for {email}")
            return True

        except Exception as time_error:
            print(f"‚ùå Time parsing error: {time_error}")
            return False

    except Exception as e:
        print(f"‚ùå Token verification error: {e}")
        return False

def send_verification_email_mailgun(email, first_name=""):
    """Send verification email using Mailgun - IMPROVED VERSION WITH DEBUGGING"""
    try:
        print(f"üîß DEBUG: === Starting email send process ===")
        print(f"üîß DEBUG: Email: {email}")
        print(f"üîß DEBUG: First name: {first_name}")

        # Step 1: Validate environment variables
        if not MAILGUN_API_KEY:
            print(f"‚ùå DEBUG: MAILGUN_API_KEY is missing or empty")
            return {"success": False, "message": "Mailgun API key not configured"}

        if not MAILGUN_DOMAIN:
            print(f"‚ùå DEBUG: MAILGUN_DOMAIN is missing or empty")
            return {"success": False, "message": "Mailgun domain not configured"}

        print(f"‚úÖ DEBUG: Environment variables present")
        print(f"üîß DEBUG: API Key length: {len(MAILGUN_API_KEY)}")
        print(f"üîß DEBUG: Domain: {MAILGUN_DOMAIN}")
        print(f"üîß DEBUG: Base URL: {MAILGUN_BASE_URL}")

        # Step 2: Generate verification token
        print(f"üîß DEBUG: Generating verification token...")
        verification_token = generate_verification_token_v2(email)
        if not verification_token:
            print(f"‚ùå DEBUG: Token generation failed")
            return {"success": False, "message": "Failed to generate verification token"}

        print(f"‚úÖ DEBUG: Token generated successfully")

        # Step 3: Build verification URL
        verification_url = f"{VERIFICATION_BASE_URL}/verify-email?email={email}&token={verification_token}"
        print(f"üîß DEBUG: Verification URL: {verification_url}")

        # Step 4: Prepare email content
        print(f"üîß DEBUG: Preparing email content...")

        # Simplified welcome text to avoid f-string issues
        if first_name:
            welcome_text = f"Welcome {first_name}!"
        else:
            welcome_text = "Welcome!"

        print(f"üîß DEBUG: Welcome text: {welcome_text}")

        # Professional HTML Email Template (simplified to avoid f-string errors)
        html_content = f"""<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Verify Your Solthron Account</title>
</head>
<body style="margin: 0; padding: 0; font-family: Arial, sans-serif; background-color: #f4f4f4;">
    <div style="max-width: 600px; margin: 0 auto; background-color: #ffffff; padding: 20px;">
        <!-- Header -->
        <div style="text-align: center; padding: 20px 0; border-bottom: 2px solid #ffff00;">
            <h1 style="color: #333; margin: 0; font-size: 28px;">
                <span style="color: #ffff00;">‚ö°</span> Solthron
            </h1>
            <p style="color: #666; margin: 5px 0 0 0; font-size: 14px;">
                Stop Overthinking AI Conversations
            </p>
        </div>

        <!-- Content -->
        <div style="padding: 40px 20px;">
            <h2 style="color: #333; margin-bottom: 20px;">{welcome_text} üöÄ</h2>

            <p style="color: #555; line-height: 1.6; font-size: 16px;">
                Thanks for signing up for Solthron! You're one step away from supercharging your AI conversations.
            </p>

            <p style="color: #555; line-height: 1.6; font-size: 16px;">
                Click the button below to verify your email address and start optimizing your prompts:
            </p>

            <!-- CTA Button -->
            <div style="text-align: center; margin: 30px 0;">
                <a href="{verification_url}"
                   style="background-color: #ffff00; color: #000; padding: 15px 30px; text-decoration: none; border-radius: 5px; font-weight: bold; font-size: 16px; display: inline-block; border: 2px solid #ffff00;">
                    Verify Email Address ‚úÖ
                </a>
            </div>

            <p style="color: #777; font-size: 14px; line-height: 1.5;">
                If the button doesn't work, copy and paste this link into your browser:
            </p>
            <p style="background-color: #f8f8f8; padding: 10px; border-radius: 4px; word-break: break-all; font-size: 12px; color: #555;">
                {verification_url}
            </p>
        </div>

        <!-- Footer -->
        <div style="background-color: #f8f8f8; padding: 20px; text-align: center; border-top: 1px solid #eee;">
            <p style="margin: 0; color: #666; font-size: 14px;">
                This verification link expires in 24 hours.
            </p>
            <p style="margin: 10px 0 0 0; color: #666; font-size: 12px;">
                ¬© 2025 Solthron. Made for better AI conversations.
            </p>
        </div>
    </div>
</body>
</html>"""

        # Plain text fallback
        text_content = f"""
{welcome_text}

Thanks for signing up! Click the link below to verify your email address:

{verification_url}

This link expires in 24 hours.

Once verified, you can start optimizing your AI conversations with our Chrome extension.

- Solthron Team
"""

        print(f"‚úÖ DEBUG: Email content prepared")

        # Step 5: Prepare Mailgun request
        mailgun_url = f"{MAILGUN_BASE_URL}/{MAILGUN_DOMAIN}/messages"
        print(f"üîß DEBUG: Mailgun URL: {mailgun_url}")

        email_data = {
            "from": f"Solthron <noreply@{MAILGUN_DOMAIN}>",
            "to": [email],
            "subject": "üöÄ Verify Your Solthron Account - Start Optimizing AI Conversations",
            "text": text_content,
            "html": html_content,
            "o:tag": ["verification", "signup"],
            "o:tracking": "yes"
        }

        print(f"üîß DEBUG: Email data prepared")
        print(f"üîß DEBUG: From: {email_data['from']}")
        print(f"üîß DEBUG: To: {email_data['to']}")
        print(f"üîß DEBUG: Subject: {email_data['subject']}")

        # Step 6: Send email via Mailgun
        print(f"üîß DEBUG: Sending request to Mailgun...")

        response = requests.post(
            mailgun_url,
            auth=("api", MAILGUN_API_KEY),
            data=email_data,
            timeout=30  # Add timeout
        )

        print(f"üîß DEBUG: Mailgun response status: {response.status_code}")
        print(f"üîß DEBUG: Mailgun response text: {response.text}")

        if response.status_code == 200:
            print(f"‚úÖ Verification email sent successfully to {email}")
            return {"success": True, "message": "Verification email sent"}
        else:
            print(f"‚ùå Mailgun error: {response.status_code} - {response.text}")
            return {"success": False, "message": f"Mailgun API error: {response.status_code}"}

    except requests.exceptions.Timeout:
        print(f"‚ùå Mailgun request timeout")
        return {"success": False, "message": "Email service timeout"}
    except requests.exceptions.ConnectionError:
        print(f"‚ùå Mailgun connection error")
        return {"success": False, "message": "Failed to connect to email service"}
    except requests.exceptions.RequestException as e:
        print(f"‚ùå Mailgun request error: {e}")
        return {"success": False, "message": f"Email service error: {str(e)}"}
    except Exception as e:
        print(f"‚ùå Unexpected error in send_verification_email_mailgun: {e}")
        print(f"‚ùå Error type: {type(e).__name__}")

# ============================================
# END MAILGUN EMAIL FUNCTIONS
# ============================================

# NEW AUTHENTICATION ENDPOINTS
@app.route('/auth/login', methods=['POST'])
def auth_login():
    """Handle login and return JWT token"""
    try:
        if not FIREBASE_ENABLED:
            return jsonify({'error': 'Authentication not available'}), 503

        data = request.get_json()
        email = data.get('email')
        password = data.get('password')

        if not email or not password:
            return jsonify({'error': 'Email and password required'}), 400

        # Check if user exists in Firestore
        users_ref = db.collection('users')
        query = users_ref.where('email', '==', email).limit(1)
        users = query.stream()

        user_doc = None
        for user in users:
            user_doc = user
            break

        if not user_doc:
            return jsonify({'error': 'User not found'}), 401

        user_data = user_doc.to_dict()

        # Create JWT token
        token_payload = {
            'uid': user_doc.id,
            'email': email,
            'exp': datetime.datetime.utcnow() + datetime.timedelta(days=30)
        }

        token = jwt.encode(token_payload, 'your-secret-key', algorithm='HS256')

        return jsonify({
            'success': True,
            'token': token,
            'user': {
                'uid': user_doc.id,
                'email': email,
                'credits': user_data.get('credits', 0)
            }
        })

    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/user-credits', methods=['GET'])
def get_user_credits():
    """Get user's current credit balance"""
    try:
        if not FIREBASE_ENABLED:
            return jsonify({'credits': 999999})  # Unlimited for testing

        auth_header = request.headers.get('Authorization')
        if not auth_header or not auth_header.startswith('Bearer '):
            return jsonify({'error': 'No valid authorization token'}), 401

        token = auth_header[7:]  # Remove 'Bearer '
        user_info = verify_auth_token(token)

        if not user_info:
            return jsonify({'error': 'Invalid token'}), 401

        credits = user_info['data'].get('credits', 0)
        return jsonify({'credits': credits})

    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/deduct-credits', methods=['POST'])
def deduct_credits():
    """Deduct credits for a feature"""
    try:
        if not FIREBASE_ENABLED:
            return jsonify({'success': True, 'remaining': 999999})

        auth_header = request.headers.get('Authorization')
        if not auth_header or not auth_header.startswith('Bearer '):
            return jsonify({'error': 'No valid authorization token'}), 401

        token = auth_header[7:]
        user_info = verify_auth_token(token)

        if not user_info:
            return jsonify({'error': 'Invalid token'}), 401

        data = request.get_json()
        feature_mode = data.get('feature', 'unknown')

        result = check_and_deduct_credits(user_info['uid'], feature_mode)
        return jsonify(result)

    except Exception as e:
        return jsonify({'error': str(e)}), 500

# YOUR EXISTING AI PROCESSING FUNCTIONS (keeping them exactly the same)
def create_enhanced_rewrite(topic, tone, length, mode='enhance'):
    if mode == 'cot':
        fixed_template = f"""Original User Request:
{topic}

INITIATING CHAIN OF THOUGHT ANALYSIS...

LAYER 1: CORE DECONSTRUCTION
‚Üí What is the fundamental purpose behind this task?
‚Üí What unstated requirements might exist?
‚Üí What potential angles are being overlooked?
‚Üí What unique value can be uncovered?

LAYER 2: EXPANSION OF POSSIBILITIES
Branch A: Conventional Path
   ‚Üí Standard approach analysis
   ‚Üí Expected outcomes
   ‚Üí Limitations identified

Branch B: Innovation Path
   ‚Üí Unconventional angles
   ‚Üí Creative possibilities
   ‚Üí Breakthrough potential

Branch C: Hybrid Solutions
   ‚Üí Best elements fusion
   ‚Üí Enhanced approaches
   ‚Üí Optimal combinations

LAYER 3: DEPTH EXPLORATION
1. Knowledge Mining
   ‚Üí Core principles
   ‚Üí Hidden connections
   ‚Üí Advanced concepts
   ‚Üí Expert insights

2. Pattern Recognition
   ‚Üí Success elements
   ‚Üí Failure points
   ‚Üí Optimization opportunities
   ‚Üí Strategic advantages

3. Impact Analysis
   ‚Üí Immediate effects
   ‚Üí Long-term implications
   ‚Üí Ripple consequences
   ‚Üí Value maximization

LAYER 4: SYNTHESIS & ELEVATION
‚Ä¢ Merge all insights into cohesive strategy
‚Ä¢ Identify breakthrough opportunities
‚Ä¢ Eliminate potential weaknesses
‚Ä¢ Enhance core strengths
‚Ä¢ Push beyond obvious solutions

EXECUTION FRAMEWORK:
1. Foundation Building
   ‚Üí Establish core elements
   ‚Üí Set up key structures
   ‚Üí Create support systems

2. Enhancement Integration
   ‚Üí Add innovative elements
   ‚Üí Incorporate unique angles
   ‚Üí Blend creative solutions

3. Excellence Amplification
   ‚Üí Optimize all components
   ‚Üí Maximize impact points
   ‚Üí Elevate quality levels

FINAL ACCELERATION:
‚Üí Challenge every assumption
‚Üí Push every boundary
‚Üí Exceed all expectations
‚Üí Transform basic into exceptional
‚Üí Elevate ordinary to extraordinary

Now, armed with this comprehensive analytical framework, return to:
{topic}

EXECUTE WITH MAXIMUM CAPABILITY AND CREATIVITY.
Transform this task beyond its basic form into something extraordinary.
Push every boundary. Challenge every norm. Create something remarkable.

[Proceed with execution using all layers of analysis above]"""

        return {
            "prompt": fixed_template,
            "status": "success",
            "metadata": {
                "topic": topic,
                "tone": tone,
                "mode": "cot"
            }
        }

    else:
        system_message = """You are an expert at reframing text to make it clear, concise, and actionable.
[System message content...]"""  # System message content as before

        detail_mapping = {
            "concise": """[Concise template content...]""",
            "balanced": """[Balanced template content...]""",
            "detailed": """[Detailed template content...]"""
        }

        user_message = detail_mapping.get(length, detail_mapping["balanced"]).format(
            topic=topic, tone=tone
        )

        return {
            "system_message": system_message,
            "user_message": user_message
        }

def process_reframe_request(client, topic, tone, length):
    if tone.startswith('reframe_'):
        tone = tone.split('_')[1]

    template = create_tone_specific_prompt(topic, tone, length)
    if not template:
        raise ValueError(f"Unsupported tone: {tone}")

    response = client.chat.completions.create(
        model="chatgpt-4o-latest",
        messages=[
            {"role": "system", "content": template["system"]},
            {"role": "user", "content": template["user"]},
            {"role": "system", "content": "Important: Output must match requested format exactly."}
        ],
        temperature=0.3
    )

    return {
        'prompt': response.choices[0].message.content,
        'status': 'success',
        'metadata': {
            'topic': topic,
            'tone': tone,
            'mode': f'reframe_{tone}'
        }
    }

def create_tone_specific_prompt(topic, tone, length):
    tone_templates = {
        "casual": {
            "system": "Your only task is to transform the text into simple tone, only tranform/rephrase, ONLY rewrite the exact same content, dont answer it as a question, If the text is a question, keep it as a question but make it simple",
            "user": f"Make this casual and friendly:\n{topic}"
        },
        "technical": {
            "system": "Your only task is to Transform text into technical tone,only tranform/rephrase, ONLY rewrite the exact same content, dont answer it as a question, even if the highlighted text is a question, keep it as a question but make it simple ",
            "user": f"Make this technical:\n{topic}"
        },
        "professional": {
            "system": "Transform text into professional tone, only tranform/rephrase, dont answer it as a question, even if the highlighted text is a question, you will only reframe it",
            "user": f"Make this professional:\n{topic}"
        },
        "eli5": {
            "system": "Transform text for a 5-year-old understanding, only tranform/rephrase, dont answer it as a question, even if the highlighted text is a question, you will only reframe it",
            "user": f"Rewrite this for a 5-year-old:\n{topic}"
        },
        "short": {
            "system": "Make text shorter while keeping main points, only make it short, dont answer it as a question, even if the highlighted text is a question, you will only reframe it",
            "user": f"Make this shorter but keep key points:\n{topic}"
        },
        "long": {
            "system": "Expand text with more details, only make it long by adding 2 to 3 lines more and dont answer it as a question, even if the highlighted text is a question, you will only reframe it",
            "user": f"Make this longer and more detailed:\n{topic}"
        }
    }
    return tone_templates.get(tone)

def create_explain_prompt(topic, mode):
    explain_templates = {
        "explain_meaning": {
            "system": """Provide clear, direct explanations of meanings. Guidelines:
- Give straightforward definitions
- Explain key concepts clearly
- Use simple language
- Keep output balanced in length (2-3 short paragraphs)
- No markdown, bullets, or special formatting""",
            "user": f"What does this mean:\n{topic}"
        },
        "explain_example": {
            "system": """Explain concepts through clear examples. Guidelines:
- Use one clear, relevant example
- Connect example to the concept
- Keep explanation practical
- Maintain balanced length (2-3 short paragraphs)
- No markdown, bullets, or special formatting""",
            "user": f"Provide an example that explains:\n{topic}"
        },
        "explain_eli5": {
            "system": """Explain concepts in child-friendly terms. Guidelines:
- Use very simple words
- Give relatable examples
- Keep sentences short
- Maintain balanced length (2-3 short paragraphs)
- No markdown, bullets, or special formatting""",
            "user": f"Explain this to a young child:\n{topic}"
        }
    }
    return explain_templates.get(mode)

def process_image_variation(client, image_data, mode):
    image_templates = {
        "image_caption": {
            "system": "Generate a concise, descriptive caption for this image.",
            "max_tokens": 50
        },
        "image_prompt": {
            "system": "Generate a detailed prompt that describes this image for AI image generation.",
            "max_tokens": 100
        }
    }

    template = image_templates.get(mode, {
        "system": "Default image processing system message",
        "max_tokens": 50
    })

    response = client.chat.completions.create(
        model="chatgpt-4o-latest",
        messages=[
            {"role": "system", "content": template["system"]},
            {"role": "user", "content": [
                {"type": "text", "text": "Process this image:"},
                {"type": "image_url", "image_url": {"url": image_data}}
            ]}
        ],
        max_tokens=template["max_tokens"]
    )

    return {
        'prompt': response.choices[0].message.content,
        'status': 'success',
        'metadata': {'mode': mode}
    }

def extract_questions_from_text(text):
    """Extract questions from AI response when JSON parsing fails"""
    questions = []
    lines = text.split('\n')

    for line in lines:
        line = line.strip()
        if '?' in line and len(line) > 20:
            # Clean the question
            clean_q = line

            # Remove common prefixes and artifacts
            prefixes = ['"text":', 'text:', '"', "'", '-', '‚Ä¢', '*', '1.', '2.', '3.', '4.', '5.']
            for prefix in prefixes:
                if clean_q.startswith(prefix):
                    clean_q = clean_q[len(prefix):].strip()

            # Remove trailing punctuation except ?
            clean_q = clean_q.rstrip('",\'"').strip()

            # Ensure it looks like a question
            if clean_q and clean_q.endswith('?') and len(clean_q) > 15:
                questions.append({
                    "text": clean_q,
                    "type": "strategic"
                })

    # If no questions extracted, provide high-quality defaults
    if len(questions) == 0:
        questions = [
            {"text": "What underlying assumptions in this approach should be validated or challenged?", "type": "assumption"},
            {"text": "What alternative strategies or methodologies could achieve similar outcomes?", "type": "alternative"},
            {"text": "What would be the key implementation challenges and success factors?", "type": "implementation"}
        ]

    return questions[:3]

def parse_json_response_enhanced(ai_response):
    """Enhanced JSON parsing for GPT-4.1's higher quality output"""

    # GPT-4.1 should produce cleaner JSON, but still handle edge cases
    clean_response = ai_response.strip()

    # Remove markdown code blocks if present
    if "```json" in clean_response:
        clean_response = clean_response.split("```json")[1].split("```")[0].strip()
    elif "```" in clean_response:
        parts = clean_response.split("```")
        if len(parts) >= 3:
            clean_response = parts[1].strip()

    # Find JSON object boundaries
    start_idx = clean_response.find('{')
    if start_idx == -1:
        raise json.JSONDecodeError("No JSON found", clean_response, 0)

    # Find the matching closing brace
    brace_count = 0
    end_idx = -1
    in_string = False
    escape_next = False

    for i in range(start_idx, len(clean_response)):
        char = clean_response[i]

        if escape_next:
            escape_next = False
            continue

        if char == '\\' and in_string:
            escape_next = True
            continue

        if char == '"':
            in_string = not in_string
            continue

        if not in_string:
            if char == '{':
                brace_count += 1
            elif char == '}':
                brace_count -= 1
                if brace_count == 0:
                    end_idx = i + 1
                    break

    if end_idx == -1:
        raise json.JSONDecodeError("Incomplete JSON", clean_response, start_idx)

    json_str = clean_response[start_idx:end_idx]
    return json.loads(json_str)

def create_gpt41_fallback_prompts_clean(original_text):
    """Create high-quality fallback prompts WITHOUT including the original text"""

    # Analyze text type for better fallbacks
    text_lower = original_text.lower()

    if any(keyword in text_lower for keyword in ['function', 'class', 'def', 'var', 'const', 'import']):
        content_type = "code"
    elif any(keyword in text_lower for keyword in ['write', 'blog', 'article', 'content', 'copy']):
        content_type = "writing"
    elif original_text.endswith('?') or 'help' in text_lower:
        content_type = "prompt"
    else:
        content_type = "content"

    fallback_prompts = [
        {
            "prompt": f"Enhance this {content_type} by making it more precise, detailed, and actionable with specific examples and clear structure",
            "focus_area": "precision_and_clarity",
            "expected_impact": "Improved clarity and specificity",
            "priority": "high"
        },
        {
            "prompt": f"Improve this {content_type} by adding context, supporting details, and better organization to increase engagement",
            "focus_area": "depth_and_structure",
            "expected_impact": "Enhanced depth and organization",
            "priority": "high"
        },
        {
            "prompt": f"Refine this {content_type} to be more engaging and persuasive with stronger language and compelling elements",
            "focus_area": "engagement",
            "expected_impact": "Increased engagement and persuasion",
            "priority": "medium"
        },
        {
            "prompt": f"Optimize this {content_type} for professional quality by following best practices and ensuring completeness",
            "focus_area": "professional_quality",
            "expected_impact": "Professional-grade output",
            "priority": "medium"
        }
    ]

    return fallback_prompts

def analyze_user_context_with_ai(input_text, platform):
    """Use AI to genuinely understand user intent and craft personalized response"""

    analysis_prompt = f"""You are an intelligent conversation assistant analyzing a user's first input to understand their goals and provide a warm, personalized response.

User's Input: "{input_text}"
Platform: {platform}

Analyze this input and provide a JSON response with:

1. DEEP INTENT ANALYSIS - What is the user truly trying to achieve? Look beyond surface keywords.
2. TOPIC DETECTION - What specific topic, subject, or theme are they working on? Be as specific as possible.
3. EMOTIONAL CONTEXT - What's their likely mood, urgency, expertise level?
4. SPECIFIC GOALS - What exact outcome do they want?
5. WARM RESPONSE - Craft a personalized, encouraging message that shows you understand their specific situation AND topic.

Requirements for topic detection:
- Extract the SPECIFIC subject matter they're discussing
- Identify industry, field, or domain if mentioned
- Note any specific products, services, or concepts
- Capture the theme or angle they're taking

Requirements for the warm response:
- KEEP IT SHORT (max 10-12 words)
- Reference the SPECIFIC TOPIC they're working on
- Sound confident and encouraging
- Use casual, friendly tone
- Show you understand without explaining everything
- Be punchy and to-the-point

JSON Format:
{{
    "intent": "specific description of what they're trying to achieve",
    "topic": "the specific topic/subject/theme they're working on",
    "topic_category": "broader category (tech, business, health, education, etc.)",
    "context": "emotional/situational context you detected",
    "user_goal": "the specific outcome they want",
    "confidence": 0.0-1.0,
    "warm_message": "personalized response referencing their specific topic and showing domain understanding"
}}

Examples of EXCELLENT short topic-aware responses:
- Input: "help me write a blog about AI in healthcare"
  Response: "AI healthcare blog - let's make it impactful!"

- Input: "craft a linkedin post about sustainable investing"
  Response: "Sustainable investing post - great timing for this!"

- Input: "help me code a React component for user authentication"
  Response: "React auth component - let's build it right!"

- Input: "help me craft a linkedin post"
  Response: "LinkedIn content - let's boost your presence!"

- Input: "write an email to my boss"
  Response: "Professional email - I'll help you nail it!"

- Input: "create a marketing strategy"
  Response: "Marketing strategy - let's drive results!"

Keep responses SHORT, CONFIDENT, and TOPIC-SPECIFIC. Max 10-12 words."""

    try:
        print(f"ü§ñ Starting AI analysis for: {input_text[:50]}...")

        response = client.chat.completions.create(
            model="chatgpt-4o-latest",
            messages=[
                {
                    "role": "system",
                    "content": "You are a highly intelligent conversation analyst. Provide deep, nuanced understanding of user intent and craft genuinely personalized responses."
                },
                {
                    "role": "user",
                    "content": analysis_prompt
                }
            ],
            temperature=0.3,
            max_tokens=500
        )

        ai_response = response.choices[0].message.content.strip()
        print(f"üß† AI Analysis Response: {ai_response}")

        # Parse the JSON response
        if "```json" in ai_response:
            ai_response = ai_response.split("```json")[1].split("```")[0]
        elif "```" in ai_response:
            ai_response = ai_response.split("```")[1].split("```")[0]

        # Find JSON boundaries
        start_idx = ai_response.find('{')
        end_idx = ai_response.rfind('}') + 1

        if start_idx != -1 and end_idx > start_idx:
            json_str = ai_response[start_idx:end_idx]
            analysis_data = json.loads(json_str)

            print(f"‚úÖ Parsed analysis:")
            print(f"   Intent: {analysis_data.get('intent', 'Unknown')}")
            print(f"   Topic: {analysis_data.get('topic', 'Unknown')}")
            print(f"   Topic Category: {analysis_data.get('topic_category', 'Unknown')}")
            print(f"   Context: {analysis_data.get('context', 'Unknown')}")
            print(f"   Goal: {analysis_data.get('user_goal', 'Unknown')}")
            print(f"   Confidence: {analysis_data.get('confidence', 0)}")
            print(f"   Message: {analysis_data.get('warm_message', 'Default')[:100]}...")

            return {
                'detected_context': analysis_data.get('intent', 'general'),
                'detected_topic': analysis_data.get('topic', 'general'),
                'topic_category': analysis_data.get('topic_category', 'general'),
                'warm_message': analysis_data.get('warm_message', 'I\'m here to help you achieve your goals!'),
                'confidence': float(analysis_data.get('confidence', 0.5)),
                'ai_analysis': {
                    'intent': analysis_data.get('intent'),
                    'topic': analysis_data.get('topic'),
                    'topic_category': analysis_data.get('topic_category'),
                    'context': analysis_data.get('context'),
                    'user_goal': analysis_data.get('user_goal')
                }
            }
        else:
            raise json.JSONDecodeError("No valid JSON found", ai_response, 0)

    except Exception as e:
        print(f"‚ùå AI analysis failed: {e}")
        print(f"‚ùå Raw AI response: {ai_response if 'ai_response' in locals() else 'No response'}")

        # Intelligent fallback based on simple analysis
        return create_intelligent_fallback(input_text, platform)

def create_intelligent_fallback(input_text, platform):
    """Create intelligent fallback when AI analysis fails"""

    input_lower = input_text.lower()
    detected_topic = 'general topic'  # Default fallback topic

    # Quick intelligent analysis
    if 'linkedin' in input_lower:
        if detected_topic != 'general topic':
            message = f"LinkedIn post on {detected_topic} - let's get engagement!"
        else:
            message = "LinkedIn content - let's boost your presence!"
        return {
            'detected_context': 'professional_content',
            'detected_topic': detected_topic,
            'warm_message': message,
            'confidence': 0.6
        }
    elif any(word in input_lower for word in ['blog', 'article', 'write']):
        if detected_topic != 'general topic':
            message = f"Blog about {detected_topic} - let's make it viral!"
        else:
            message = "Content creation - let's make it compelling!"
        return {
            'detected_context': 'content_creation',
            'detected_topic': detected_topic,
            'warm_message': message,
            'confidence': 0.6
        }
    elif any(word in input_lower for word in ['code', 'app', 'website', 'program']):
        if detected_topic != 'general topic':
            message = f"Building {detected_topic} - let's code something amazing!"
        else:
            message = "Coding project - let's build something great!"
        return {
            'detected_context': 'development',
            'detected_topic': detected_topic,
            'warm_message': message,
            'confidence': 0.6
        }
    else:
        if detected_topic != 'general topic':
            message = f"Working on {detected_topic} - I'll help optimize it!"
        else:
            message = "I'm here to help - let's get better results!"
        return {
            'detected_context': 'general',
            'detected_topic': detected_topic,
            'warm_message': message,
            'confidence': 0.5
        }

# DEBUG ENDPOINTS
@app.route('/debug-routes', methods=['GET'])
def debug_routes():
    """Debug endpoint to check which routes are loaded"""
    routes = []
    for rule in app.url_map.iter_rules():
        routes.append({
            'endpoint': rule.endpoint,
            'methods': list(rule.methods),
            'rule': str(rule)
        })
    return jsonify({'routes': routes})

@app.route('/test-convert', methods=['POST'])
def test_convert():
    """Simple test for convert functionality"""
    try:
        data = request.get_json(force=True)
        return jsonify({
            'success': True,
            'received_data': data,
            'message': 'Convert endpoint is working'
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500

# ALL YOUR EXISTING ENDPOINTS WITH CREDIT CHECKS ADDED

@app.route('/')
def home():
    return "Solthron API is running"

@app.route('/generate', methods=['POST'])
def generate():
    try:
        data = request.get_json(force=True)
        topic = data.get('topic', '').strip()
        tone = data.get('tone', 'professional')
        length = data.get('length', 'balanced')
        mode = data.get('mode', 'reframe_casual')

        if not topic:
            return jsonify({'error': 'Topic is required'}), 400

        # ADD CREDIT CHECK HERE
        credit_result = optional_credit_check(mode)
        if not credit_result['success']:
            return jsonify({
                'error': credit_result['message'],
                'credits_required': get_feature_credits(mode)
            }), 402

        # Handle reframe modes
        if mode.startswith('reframe_'):
            tone = mode.split('_')[1]
            result = process_reframe_request(client, topic, tone, length)

            # Add credit info to response
            if credit_result.get('credits_used'):
                result['credits_used'] = credit_result['credits_used']
                result['credits_remaining'] = credit_result.get('remaining')

            return jsonify(result)

        # Handle explain modes - RESTORED ORIGINAL TEMPLATES
        if mode.startswith('explain_'):
            if mode == 'explain_meaning':
                # ORIGINAL explain_meaning template
                template = f"""Definition:
[Concise one-line definition of the core concept]

Domain Meanings & Usage:
| [Domain1]: [Specific meaning in this domain]
  "[Example sentence showing usage]"

| [Domain2]: [Specific meaning in this domain]
  "[Example sentence showing usage]"

| [Domain3]: [Specific meaning in this domain]
  "[Example sentence showing usage]"

| [Domain4]: [Specific meaning in this domain]
  "[Example sentence showing usage]"

Related:
[3-4 closely related terms, comma-separated]"""

                response = client.chat.completions.create(
                    model="chatgpt-4o-latest",
                    messages=[
                        {
                            "role": "system",
                            "content": "Generate concise, structured explanations following the exact template format. Include relevant domain-specific meanings and authentic usage examples."
                        },
                        {
                            "role": "user",
                            "content": f"Explain this term:\n{topic}\n\nUse template:\n{template}"
                        }
                    ],
                    temperature=0.3,
                    max_tokens=400
                )

            elif mode == 'explain_story':
                # ORIGINAL explain_story template
                template = f"""Core Concept:
[One-line explanation of what it is]

Story:
[3-4 sentences that naturally explain the concept through a relatable narrative]"""

                response = client.chat.completions.create(
                    model="chatgpt-4o-latest",
                    messages=[
                        {"role": "system", "content": "Create a concise story that explains the concept naturally, without bullet points or sections."},
                        {"role": "user", "content": f"Explain this through a story:\n{topic}\n\nUse template:\n{template}"}
                    ],
                    temperature=0.3,
                    max_tokens=400
                )

            elif mode == 'explain_eli5':
                # ORIGINAL explain_eli5 approach
                response = client.chat.completions.create(
                    model="chatgpt-4o-latest",
                    messages=[
                        {"role": "system", "content": "Explain concepts using simple words, fun analogies, and examples that a 5-year-old would understand. Use short sentences and friendly language."},
                        {"role": "user", "content": f"Explain this to a 5-year-old:\n{topic}"}
                    ],
                    temperature=0.3,
                    max_tokens=400
                )

            else:
                # Fallback for any other explain modes
                template = create_explain_prompt(topic, mode)
                response = client.chat.completions.create(
                    model="chatgpt-4o-latest",
                    messages=[
                        {"role": "system", "content": template["system"]},
                        {"role": "user", "content": template["user"]}
                    ],
                    temperature=0.7
                )

            result = {
                'prompt': response.choices[0].message.content,
                'status': 'success',
                'metadata': {'mode': mode}
            }

            if credit_result.get('credits_used'):
                result['credits_used'] = credit_result['credits_used']
                result['credits_remaining'] = credit_result.get('remaining')

            return jsonify(result)

        # Handle convert modes - RESTORED ORIGINAL TEMPLATES
        if mode.startswith('convert_'):
            try:
                if mode == 'convert_concise':
                    # ORIGINAL convert_concise template
                    template = f"""You will convert the following text into a clear, concise prompt.

Format Guidelines:
- One clear task statement
- Maximum 2-3 essential requirements
- No additional explanations or examples
- Keep total length under 5 lines
- Maintain professional tone

Structure:
Task: [One clear sentence]
Requirements:
1. [First key requirement]
2. [Second key requirement]
3. [Third key requirement - if absolutely necessary]

Format Requirements:
- Maximum 3 sentences
- No bullet points
- No examples unless critical
- Focus on core request

Original Text:
{topic}

Enhance this text into a clear, focused prompt that could be given to an AI system."""

                elif mode == 'convert_balanced':
                    # ORIGINAL convert_balanced template
                    template = f"""You will help convert the following text into a balanced, well-structured prompt.

Format Guidelines:
- Clear task definition
- Do not use afterrisks
- 4-5 key requirements
- One brief example
- Keep total length under 10 lines

Structure:
Task: [Clear task description]

Requirements:
1. [First requirement]
2. [Second requirement]
3. [Third requirement]
4. [Fourth requirement]
5. [Optional fifth requirement]

Example:
Scenario: [Brief example scenario]
Input: [Sample input]
Output: [Expected output]

Output Format: [Desired format]

Original Text:
{topic}

Transform this text into a balanced prompt that provides clear direction while maintaining essential context."""

                else:  # convert_detailed
                    # ORIGINAL convert_detailed template
                    template = f"""Create a comprehensive prompt about {topic}.

Format Guidelines:
- Detailed task explanation
- Do not use afterrisks
- Specific requirements and constraints
- Step-by-step guidance
- Clear examples
- Structured sections

Structure:
Task: [Comprehensive task description]

Requirements:
1. [First requirement with explanation]
2. [Second requirement with explanation]
3. [Third requirement with explanation]
[Continue with all necessary requirements]

Steps:
1. [First step with guidance]
2. [Second step with guidance]
3. [Third step with guidance]
[Continue with all necessary steps]

Examples:
1. Example Scenario: [Specific example]
   Input: [Sample input]
   Output: [Expected output]
2. [Additional example if needed]

Output Format: [Specific format requirements]

Structure Guidelines:
- Clear section headers
- Multiple related examples
- Step-by-step instructions where relevant
- Explicit success criteria
- Edge cases and exceptions

Original Text:
{topic}

Transform this text into a detailed prompt that leaves no room for ambiguity while maintaining clarity and purpose."""

                response = client.chat.completions.create(
                    model="chatgpt-4o-latest",
                    messages=[
                        {
                            "role": "system",
                            "content": "You are an expert at creating clear, effective prompts."
                        },
                        {
                            "role": "user",
                            "content": template
                        }
                    ],
                    temperature=0.3
                )

                result = {
                    'prompt': response.choices[0].message.content,
                    'status': 'success',
                    'metadata': {'mode': mode, 'original_text': topic}
                }

                if credit_result.get('credits_used'):
                    result['credits_used'] = credit_result['credits_used']
                    result['credits_remaining'] = credit_result.get('remaining')

                return jsonify(result)

            except Exception as e:
                return jsonify({'error': str(e), 'status': 'error'}), 500

        # Handle image modes
        if mode.startswith('image_'):
            result = process_image_variation(client, topic, mode)

            if credit_result.get('credits_used'):
                result['credits_used'] = credit_result['credits_used']
                result['credits_remaining'] = credit_result.get('remaining')

            return jsonify(result)

        # Handle template modes (only cot now)
        if mode in ['cot']:
            result = create_enhanced_rewrite(topic, tone, length, mode)

            if credit_result.get('credits_used'):
                result['credits_used'] = credit_result['credits_used']
                result['credits_remaining'] = credit_result.get('remaining')

            return jsonify(result)

        # Default processing
        prompt_data = create_enhanced_rewrite(topic, tone, length)
        response = client.chat.completions.create(
            model="chatgpt-4o-latest",
            messages=[
                {"role": "system", "content": prompt_data["system_message"]},
                {"role": "user", "content": prompt_data["user_message"]}
            ],
            temperature=0.7
        )

        result = {
            'prompt': response.choices[0].message.content,
            'status': 'success',
            'metadata': {
                'topic': topic,
                'tone': tone,
                'mode': mode
            }
        }

        if credit_result.get('credits_used'):
            result['credits_used'] = credit_result['credits_used']
            result['credits_remaining'] = credit_result.get('remaining')

        return jsonify(result)

    except Exception as e:
        logging.error(f"Error generating prompt: {str(e)}")
        return jsonify({
            'error': 'Failed to generate prompt',
            'details': str(e)
        }), 500

@app.route('/generate-image', methods=['POST'])
def generate_image_prompt():
    try:
        # ADD CREDIT CHECK
        credit_result = optional_credit_check('image_prompt')
        if not credit_result['success']:
            return jsonify({
                'error': credit_result['message'],
                'credits_required': get_feature_credits('image_prompt')
            }), 402

        data = request.get_json(force=True)
        image_url = data.get('image')

        universal_prompt = """Analyze this image with extreme thoroughness and precision. Examine every single visual element, no matter how minute. Study the image as if you need to recreate it perfectly from memory. Provide output in this exact format:

Description: [4-5 line comprehensive description capturing the complete scene, all subjects, actions, and significant visual elements in detail]

Primary Subject(s): [main subject(s) with detailed description - pose, body language, facial expressions, age estimation, gender, ethnicity if apparent, clothing brand/style/condition, accessories, jewelry, footwear, hair style/color, makeup, gestures, what they're doing/holding]

Secondary Elements: [people, animals, or objects in background/periphery with their positions, actions, and details]

Environment/Setting: [specific location type, indoor/outdoor, architectural style, room type, landscape features, weather conditions, season indicators, time of day evidence, geographical clues, cultural context]

Colors & Visual Palette: [dominant colors, accent colors, color harmony, saturation levels, color temperature (warm/cool), specific color names, color distribution across image]

Lighting Analysis: [light source type (natural/artificial), direction (front/back/side), intensity (harsh/soft), quality (diffused/direct), shadows (hard/soft), highlights, reflections, ambient lighting, contrast levels]

Materials & Textures: [fabric types, surface materials, texture quality (smooth/rough/glossy/matte), material condition (new/worn/damaged), patterns, weaves, finishes]

Style & Technique: [photography style, artistic medium, visual technique, filter effects, processing style, camera type indicators, lens characteristics, depth of field, bokeh quality]

Composition & Framing: [camera angle (high/low/eye level), perspective (wide/close-up/macro), framing (tight/loose), rule of thirds application, leading lines, symmetry/asymmetry, balance, focal points, negative space usage]

Technical Quality: [image resolution indicators, sharpness, noise levels, compression artifacts, dynamic range, exposure quality] --ar [width:height ratio] --v 5.2

Text & Graphics: [any visible text (exact words), fonts, signs, labels, logos, brand names, symbols, graphics, artwork, posters, screens, digital displays]

Spatial Relationships: [how objects relate to each other, size comparisons, distance relationships, layering (foreground/midground/background), overlap patterns, perspective cues]

Motion & Action: [any movement indicators, blur patterns, action sequences, dynamic elements, static vs moving elements]

Mood & Atmosphere: [emotional tone, energy level, ambiance, psychological impact, cultural mood, formality level, tension/relaxation]

Temporal Indicators: [time period clues, historical markers, technology visible, fashion era, architectural period, anachronisms]

Fine Details: [small background objects, wear patterns, aging signs, scratches/damage, reflections in surfaces, shadows of unseen objects, partial text, edge details, corner elements, pattern specifics, brand markings, serial numbers, dates, signatures]

Anomalies & Unique Features: [anything unusual, unexpected, hidden elements, visual tricks, easter eggs, inconsistencies, artistic choices, creative elements, surreal aspects]

Do not use afterrisks in the output"""

        response = client.chat.completions.create(
            model="chatgpt-4o-latest",
            messages=[
                {
                    "role": "system",
                    "content": "Generate precise image analysis following the universal prompt format."
                },
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": universal_prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": image_url,
                                "detail": "high"
                            }
                        }
                    ]
                }
            ],
            max_tokens=500
        )

        result = {
            'prompt': response.choices[0].message.content,
            'status': 'success'
        }

        if credit_result.get('credits_used'):
            result['credits_used'] = credit_result['credits_used']
            result['credits_remaining'] = credit_result.get('remaining')

        return jsonify(result)

    except Exception as e:
        logging.error(f"Error: {str(e)}")
        return jsonify({'error': str(e), 'status': 'error'}), 500

@app.route('/generate-caption', methods=['POST'])
def generate_caption():
    try:
        # ADD CREDIT CHECK
        credit_result = optional_credit_check('image_caption')
        if not credit_result['success']:
            return jsonify({
                'error': credit_result['message'],
                'credits_required': get_feature_credits('image_caption')
            }), 402

        data = request.get_json(force=True)
        image_url = data.get('image')

        social_caption_prompt = """Analyze this image and generate platform-specific captions in the following format, do not use asterisks::

Instagram:
[Write an engaging, conversational caption with emojis]
.
.
.
#[relevant hashtags, maximum 15]

Facebook:
[Write a longer, more detailed description that tells a story and encourages engagement]

Twitter/X:
[Write a concise, catchy caption within 280 characters, include 2-3 relevant hashtags]

LinkedIn:
[Write a professional caption that provides business context or insight]
‚Üí [Add one key professional takeaway or insight]
---
#[3-4 relevant professional hashtags]"""

        response = client.chat.completions.create(
            model="chatgpt-4o-latest",
            messages=[
                {
                    "role": "system",
                    "content": "Generate engaging, platform-optimized social media captions."
                },
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": social_caption_prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": image_url,
                                "detail": "high"
                            }
                        }
                    ]
                }
            ],
            max_tokens=500
        )

        result = {
            'prompt': response.choices[0].message.content,
            'status': 'success'
        }

        if credit_result.get('credits_used'):
            result['credits_used'] = credit_result['credits_used']
            result['credits_remaining'] = credit_result.get('remaining')

        return jsonify(result)

    except Exception as e:
        logging.error(f"Error: {str(e)}")
        return jsonify({'error': str(e), 'status': 'error'}), 500

@app.route('/explain-meaning', methods=['POST'])
def explain_meaning():
    # ADD CREDIT CHECK
    credit_result = optional_credit_check('explain_meaning')
    if not credit_result['success']:
        return jsonify({
            'error': credit_result['message'],
            'credits_required': get_feature_credits('explain_meaning')
        }), 402

    data = request.get_json(force=True)
    text = data.get('text', '').strip()

    # ORIGINAL explain_meaning template
    template = f"""Definition:
[Concise one-line definition of the core concept]

Domain Meanings & Usage:
| [Domain1]: [Specific meaning in this domain]
  "[Example sentence showing usage]"

| [Domain2]: [Specific meaning in this domain]
  "[Example sentence showing usage]"

| [Domain3]: [Specific meaning in this domain]
  "[Example sentence showing usage]"

| [Domain4]: [Specific meaning in this domain]
  "[Example sentence showing usage]"

Related:
[3-4 closely related terms, comma-separated]"""

    response = client.chat.completions.create(
        model="chatgpt-4o-latest",
        messages=[
            {
                "role": "system",
                "content": "Generate concise, structured explanations following the exact template format. Include relevant domain-specific meanings and authentic usage examples."
            },
            {
                "role": "user",
                "content": f"Explain this term:\n{text}\n\nUse template:\n{template}"
            }
        ],
        temperature=0.3,
        max_tokens=400
    )

    result = {'explanation': response.choices[0].message.content}

    if credit_result.get('credits_used'):
        result['credits_used'] = credit_result['credits_used']
        result['credits_remaining'] = credit_result.get('remaining')

    return jsonify(result)

@app.route('/explain-story', methods=['POST'])
def explain_story():
    # ADD CREDIT CHECK
    credit_result = optional_credit_check('explain_story')
    if not credit_result['success']:
        return jsonify({
            'error': credit_result['message'],
            'credits_required': get_feature_credits('explain_story')
        }), 402

    data = request.get_json(force=True)
    text = data.get('text', '').strip()

    # ORIGINAL explain_story template
    template = f"""Core Concept:
[One-line explanation of what it is]

Story:
[3-4 sentences that naturally explain the concept through a relatable narrative]"""

    response = client.chat.completions.create(
        model="chatgpt-4o-latest",
        messages=[
            {"role": "system", "content": "Create a concise story that explains the concept naturally, without bullet points or sections."},
            {"role": "user", "content": f"Explain this through a story:\n{text}\n\nUse template:\n{template}"}
        ],
        temperature=0.3,
        max_tokens=400
    )

    result = {'explanation': response.choices[0].message.content}

    if credit_result.get('credits_used'):
        result['credits_used'] = credit_result['credits_used']
        result['credits_remaining'] = credit_result.get('remaining')

    return jsonify(result)

@app.route('/explain-eli5', methods=['POST'])
def explain_eli5():
    # ADD CREDIT CHECK
    credit_result = optional_credit_check('explain_eli5')
    if not credit_result['success']:
        return jsonify({
            'error': credit_result['message'],
            'credits_required': get_feature_credits('explain_eli5')
        }), 402

    data = request.get_json(force=True)
    text = data.get('text', '').strip()

    # ORIGINAL explain_eli5 approach
    response = client.chat.completions.create(
        model="chatgpt-4o-latest",
        messages=[
            {"role": "system", "content": "Explain concepts using simple words, fun analogies, and examples that a 5-year-old would understand. Use short sentences and friendly language."},
            {"role": "user", "content": f"Explain this to a 5-year-old:\n{text}"}
        ],
        temperature=0.3,
        max_tokens=400
    )

    result = {'explanation': response.choices[0].message.content}

    if credit_result.get('credits_used'):
        result['credits_used'] = credit_result['credits_used']
        result['credits_remaining'] = credit_result.get('remaining')

    return jsonify(result)

@app.route('/convert-concise', methods=['POST'])
def convert_concise():
    """Convert input to a concise prompt using specific strategies."""
    try:
        # ADD CREDIT CHECK
        credit_result = optional_credit_check('convert_concise')
        if not credit_result['success']:
            return jsonify({
                'error': credit_result['message'],
                'credits_required': get_feature_credits('convert_concise')
            }), 402

        data = request.get_json(force=True)
        topic = data.get('topic', '').strip()

        # ORIGINAL convert_concise template
        template = f"""You will convert the following text into a clear, concise prompt.

Format Guidelines:
- One clear task statement
- Maximum 2-3 essential requirements
- No additional explanations or examples
- Keep total length under 5 lines
- Maintain professional tone

Structure:
Task: [One clear sentence]
Requirements:
1. [First key requirement]
2. [Second key requirement]
3. [Third key requirement - if absolutely necessary]

Format Requirements:
- Maximum 3 sentences
- No bullet points
- No examples unless critical
- Focus on core request

Original Text:
{topic}

Enhance this text into a clear, focused prompt that could be given to an AI system."""

        response = client.chat.completions.create(
            model="chatgpt-4o-latest",
            messages=[
                {
                    "role": "system",
                    "content": "You are an expert at converting text into clear, concise prompts."
                },
                {
                    "role": "user",
                    "content": template
                }
            ],
            temperature=0.3
        )

        result = {
            'prompt': response.choices[0].message.content,
            'status': 'success',
            'metadata': {
                'mode': 'concise',
                'original_text': topic
            }
        }

        if credit_result.get('credits_used'):
            result['credits_used'] = credit_result['credits_used']
            result['credits_remaining'] = credit_result.get('remaining')

        return jsonify(result)

    except Exception as e:
        return jsonify({'error': str(e), 'status': 'error'}), 500

@app.route('/convert-balanced', methods=['POST'])
def convert_balanced():
    """Convert input to a balanced prompt with moderate detail."""
    try:
        # ADD CREDIT CHECK
        credit_result = optional_credit_check('convert_balanced')
        if not credit_result['success']:
            return jsonify({
                'error': credit_result['message'],
                'credits_required': get_feature_credits('convert_balanced')
            }), 402

        data = request.get_json(force=True)
        topic = data.get('topic', '').strip()

        # ORIGINAL convert_balanced template
        template = f"""You will help convert the following text into a balanced, well-structured prompt.

Format Guidelines:
- Clear task definition
- Do not use afterrisks
- 4-5 key requirements
- One brief example
- Keep total length under 10 lines

Structure:
Task: [Clear task description]

Requirements:
1. [First requirement]
2. [Second requirement]
3. [Third requirement]
4. [Fourth requirement]
5. [Optional fifth requirement]

Example:
Scenario: [Brief example scenario]
Input: [Sample input]
Output: [Expected output]

Output Format: [Desired format]

Original Text:
{topic}

Transform this text into a balanced prompt that provides clear direction while maintaining essential context."""

        response = client.chat.completions.create(
            model="chatgpt-4o-latest",
            messages=[
                {
                    "role": "system",
                    "content": "You are an expert at creating well-balanced prompts that provide the right level of detail."
                },
                {
                    "role": "user",
                    "content": template
                }
            ],
            temperature=0.4
        )

        result = {
            'prompt': response.choices[0].message.content,
            'status': 'success',
            'metadata': {
                'mode': 'balanced',
                'original_text': topic
            }
        }

        if credit_result.get('credits_used'):
            result['credits_used'] = credit_result['credits_used']
            result['credits_remaining'] = credit_result.get('remaining')

        return jsonify(result)

    except Exception as e:
        return jsonify({'error': str(e), 'status': 'error'}), 500

@app.route('/convert-detailed', methods=['POST'])
def convert_detailed():
    """Convert input to a detailed prompt with comprehensive specifications."""
    try:
        # ADD CREDIT CHECK
        credit_result = optional_credit_check('convert_detailed')
        if not credit_result['success']:
            return jsonify({
                'error': credit_result['message'],
                'credits_required': get_feature_credits('convert_detailed')
            }), 402

        data = request.get_json(force=True)
        topic = data.get('topic', '').strip()

        # ORIGINAL convert_detailed template
        template = f"""Create a comprehensive prompt about {topic}.

Format Guidelines:
- Detailed task explanation
- Do not use afterrisks
- Specific requirements and constraints
- Step-by-step guidance
- Clear examples
- Structured sections

Structure:
Task: [Comprehensive task description]

Requirements:
1. [First requirement with explanation]
2. [Second requirement with explanation]
3. [Third requirement with explanation]
[Continue with all necessary requirements]

Steps:
1. [First step with guidance]
2. [Second step with guidance]
3. [Third step with guidance]
[Continue with all necessary steps]

Examples:
1. Example Scenario: [Specific example]
   Input: [Sample input]
   Output: [Expected output]
2. [Additional example if needed]

Output Format: [Specific format requirements]

Structure Guidelines:
- Clear section headers
- Multiple related examples
- Step-by-step instructions where relevant
- Explicit success criteria
- Edge cases and exceptions

Original Text:
{topic}

Transform this text into a detailed prompt that leaves no room for ambiguity while maintaining clarity and purpose."""

        response = client.chat.completions.create(
            model="chatgpt-4o-latest",
            messages=[
                {
                    "role": "system",
                    "content": "You are an expert at creating detailed, comprehensive prompts that capture all necessary specifications, and dont use # or * in your output"
                },
                {
                    "role": "user",
                    "content": template
                }
            ],
            temperature=0.5
        )

        result = {
            'prompt': response.choices[0].message.content,
            'status': 'success',
            'metadata': {
                'mode': 'detailed',
                'original_text': topic
            }
        }

        if credit_result.get('credits_used'):
            result['credits_used'] = credit_result['credits_used']
            result['credits_remaining'] = credit_result.get('remaining')

        return jsonify(result)

    except Exception as e:
        return jsonify({'error': str(e), 'status': 'error'}), 500

# KEEP ALL YOUR EXISTING SMART FOLLOWUPS, ENHANCEMENTS, ACTIONS, AND PERSONA ENDPOINTS...

# Smart Follow-ups helper functions
def get_focus_for_session(conversation):
    """Simple rotation based on conversation hash - no storage needed"""

    focus_options = [
        "Ask about practical next steps and what to try first",
        "Ask about different ways to approach the same thing",
        "Ask about potential problems or things that might go wrong",
        "Ask about how this would work in real situations",
        "Ask about things that might be missing or overlooked",
        "Ask about what resources or help would be needed",
        "Ask about how this connects with other things they're doing",
        "Ask about how to know if it's working or successful"
    ]

    # Use conversation content to deterministically pick focus (no randomness)
    focus_index = abs(hash(conversation[:200])) % len(focus_options)
    return focus_options[focus_index]

def extract_key_terms(conversation_snippet):
    """Extract key terms from conversation for better fallback questions"""
    try:
        # Simple keyword extraction - look for capitalized words, technical terms, etc.
        import re

        # Find potential key terms (capitalized words, technical patterns)
        patterns = [
            r'\b[A-Z][a-z]+(?:\s+[A-Z][a-z]+)*\b',  # Proper nouns
            r'\b(?:API|SDK|AI|ML|UI|UX|SaaS|MVP|POC)\b',  # Common tech acronyms
            r'\b\w+(?:\.js|\.py|\.com|\.org)\b',  # File extensions, domains
            r'\b(?:React|Vue|Angular|Python|JavaScript|Node|Docker|AWS|Azure)\b'  # Common tech terms
        ]

        key_terms = []
        for pattern in patterns:
            matches = re.findall(pattern, conversation_snippet, re.IGNORECASE)
            key_terms.extend(matches)

        # Remove duplicates and return top 3
        unique_terms = list(dict.fromkeys(key_terms))
        return unique_terms[:3]

    except Exception:
        return []

def build_enhanced_prompt(conversation, focus_type):
    """Build enhanced prompt with focus rotation and specificity requirements"""

    return f"""
You're helping someone continue their conversation by suggesting 5 things they might want to explore next.

CONVERSATION:
{conversation[:1800]}

Generate 5 follow-up questions that feel natural and helpful. Mix of approaches:
- 2 practical/simple questions (what someone curious would ask)
- 2 slightly deeper questions (but still conversational)
- 1 action-oriented question (what to DO next - asking for practical steps or advice)

Guidelines:
‚úì Reference specific things mentioned in the conversation
‚úì Keep questions conversational and approachable
‚úì Ask what a curious friend might genuinely want to know
‚úì Avoid business jargon and academic language
‚úì {focus_type}

Question Style Examples:
- "Have you tried [specific approach mentioned]?"
- "What happens if [specific scenario]?"
- "Could you walk through how [specific part] works?"
- "What's been your biggest challenge with [specific thing]?"
- "Have you considered starting with [simpler version]?"

For action questions specifically - ask for practical steps:
- "What would you recommend trying first with [specific thing]?"
- "How should I get started with [specific approach]?"
- "What's the simplest way to test [specific idea]?"
- "What tools would work best for [specific task]?"

Make questions feel like natural conversation flow - what would you genuinely want to know next?

JSON format:
{{
    "questions": [
        {{"text": "Simple, curious question?", "type": "curious"}},
        {{"text": "Another practical question?", "type": "practical"}},
        {{"text": "Slightly deeper but still conversational question?", "type": "deeper"}},
        {{"text": "Another conversational exploration question?", "type": "exploration"}},
        {{"text": "What should I do/try next with [specific thing]?", "type": "action"}}
    ],
    "analysis": "What would help move this conversation forward"
}}"""

@app.route('/smart-followups', methods=['POST'])
def smart_followups():
    """Enhanced smart follow-up questions with dynamic generation"""
    try:
        logging.info("=== Enhanced smart followups request started ===")

        # ADD CREDIT CHECK
        credit_result = optional_credit_check('smart_followups')
        if not credit_result['success']:
            return jsonify({
                'error': credit_result['message'],
                'credits_required': get_feature_credits('smart_followups')
            }), 402

        # Parse request
        data = request.get_json(force=True)
        conversation = data.get('conversation', '').strip()
        platform = data.get('platform', 'unknown')

        logging.info(f"Conversation length: {len(conversation)}, Platform: {platform}")

        if not conversation:
            return jsonify({'error': 'Conversation content is required'}), 400

        # Get dynamic focus for this conversation
        focus_type = get_focus_for_session(conversation)
        logging.info(f"Selected focus: {focus_type}")

        # Build enhanced prompt with focus and specificity requirements
        analysis_prompt = build_enhanced_prompt(conversation, focus_type)

        # Use reliable models with proper error handling
        models_to_try = [
            {
                "name": "chatgpt-4o-latest",  # Start with most reliable model
                "params": {
                    "temperature": 0.3,  # Increased from 0.1 for more variation
                    "max_tokens": 1000
                }
            },
            {
                "name": "gpt-3.5-turbo",
                "params": {
                    "temperature": 0.3,
                    "max_tokens": 800
                }
            }
        ]

        response = None
        model_used = None

        # Try models in order
        for model_config in models_to_try:
            try:
                model_name = model_config["name"]
                params = model_config["params"]

                logging.info(f"Trying model: {model_name}")

                response = client.chat.completions.create(
                    model=model_name,
                    messages=[{"role": "user", "content": analysis_prompt}],
                    **params
                )

                model_used = model_name
                logging.info(f"Successfully used model: {model_name}")
                break

            except Exception as e:
                error_msg = str(e)
                logging.warning(f"Model {model_name} failed: {error_msg}")
                continue

        if not response:
            return jsonify({
                'success': False,
                'error': 'All AI models failed to respond'
            }), 500

        # Parse response
        ai_response = response.choices[0].message.content.strip()
        logging.info(f"AI Response length: {len(ai_response)}")

        try:
            # Clean and extract JSON
            clean_response = ai_response

            # Remove markdown code blocks
            if "```json" in clean_response:
                clean_response = clean_response.split("```json")[1].split("```")[0]
            elif "```" in clean_response:
                parts = clean_response.split("```")
                if len(parts) >= 3:
                    clean_response = parts[1]

            # Find JSON boundaries
            start_idx = clean_response.find('{')
            if start_idx == -1:
                raise json.JSONDecodeError("No JSON found", clean_response, 0)

            # Find matching closing brace
            brace_count = 0
            end_idx = -1
            for i in range(start_idx, len(clean_response)):
                if clean_response[i] == '{':
                    brace_count += 1
                elif clean_response[i] == '}':
                    brace_count -= 1
                    if brace_count == 0:
                        end_idx = i + 1
                        break

            if end_idx == -1:
                raise json.JSONDecodeError("Incomplete JSON", clean_response, start_idx)

            json_str = clean_response[start_idx:end_idx]
            parsed_response = json.loads(json_str)

            # Validate structure
            questions = parsed_response.get('questions', [])
            if not isinstance(questions, list) or len(questions) == 0:
                raise ValueError("No valid questions found")

            # Process and validate questions
            validated_questions = []
            for i, q in enumerate(questions[:5]):  # Changed from 3 to 5
                if isinstance(q, dict) and 'text' in q:
                    text = q['text'].strip()
                    if text and len(text) > 15:  # Minimum question length
                        if not text.endswith('?'):
                            text += '?'
                        validated_questions.append({
                            "text": text,
                            "type": q.get('type', 'strategic')
                        })

            if len(validated_questions) == 0:
                raise ValueError("No valid questions after processing")

            result = {
                'success': True,
                'questions': validated_questions,
                'analysis': parsed_response.get('analysis', 'Strategic insights generated'),
                'platform': platform,
                'model': model_used,
                'focus_used': focus_type,
                'enhanced': True
            }

            if credit_result.get('credits_used'):
                result['credits_used'] = credit_result['credits_used']
                result['credits_remaining'] = credit_result.get('remaining')

            return jsonify(result)

        except (json.JSONDecodeError, ValueError) as e:
            logging.error(f"JSON parsing failed: {str(e)}")

            # Enhanced fallback extraction with conversation context
            questions = extract_questions_from_text(ai_response)

            result = {
                'success': True,
                'questions': questions,
                'analysis': 'Strategic questions generated to enhance discussion',
                'platform': platform,
                'model': model_used,
                'focus_used': focus_type,
                'enhanced': True,
                'fallback': True
            }

            if credit_result.get('credits_used'):
                result['credits_used'] = credit_result['credits_used']
                result['credits_remaining'] = credit_result.get('remaining')

            return jsonify(result)

    except Exception as e:
        error_msg = str(e)
        error_type = type(e).__name__

        logging.error(f"=== Enhanced smart followups error ===")
        logging.error(f"Error type: {error_type}")
        logging.error(f"Error message: {error_msg}")

        return jsonify({
            'success': False,
            'error': 'Failed to generate follow-up questions',
            'details': error_msg[:200],
            'error_type': error_type
        }), 500

@app.route('/smart-enhancements', methods=['POST'])
def smart_enhancements():
    """Generate smart enhancement suggestions based on selected text"""
    try:
        logging.info("=== Smart enhancements request started ===")

        # ADD CREDIT CHECK
        credit_result = optional_credit_check('smart_enhancements')
        if not credit_result['success']:
            return jsonify({
                'error': credit_result['message'],
                'credits_required': get_feature_credits('smart_enhancements')
            }), 402

        # Parse request
        data = request.get_json(force=True)
        selected_text = data.get('text', '').strip()

        logging.info(f"Selected text length: {len(selected_text)}")

        if not selected_text:
            return jsonify({'error': 'Selected text is required'}), 400

        # Enhanced prompt that generates enhancement instructions WITHOUT including original text
        enhancement_prompt = f"""
You are an expert content strategist with deep understanding across all domains. Analyze the highlighted text and create 4 precise enhancement instructions.

HIGHLIGHTED TEXT TO ANALYZE:
{selected_text}

ANALYSIS FRAMEWORK:
1. Content Type & Purpose: What is this and what's it trying to achieve?
2. Current Quality Level: Strengths and improvement opportunities
3. Context Clues: Infer the user's likely goals and constraints
4. Enhancement Vectors: Identify the 4 most impactful improvement areas

ENHANCEMENT INSTRUCTION REQUIREMENTS:
- Each must be a clear, actionable instruction
- Focus on specific improvements, not vague suggestions
- Be immediately copy-pasteable as a prompt
- Do NOT include the original text in the instruction
- Start with action verbs like "Enhance", "Improve", "Add", "Refine"

INSTRUCTION FORMULA: "[Action verb] this [content type] by [specific improvement instructions]"

JSON FORMAT:
{{
    "content_analysis": {{
        "type": "What type of content this is",
        "purpose": "What it's trying to achieve",
        "current_quality": "Brief assessment",
        "improvement_potential": "Key areas for enhancement"
    }},
    "enhancement_prompts": [
        {{
            "prompt": "Clear enhancement instruction WITHOUT original text",
            "focus_area": "Primary improvement focus",
            "expected_impact": "What this will improve",
            "priority": "high/medium/low"
        }},
        {{
            "prompt": "Second enhancement instruction focusing on different aspect",
            "focus_area": "Different improvement aspect",
            "expected_impact": "Different improvement outcome",
            "priority": "high/medium/low"
        }},
        {{
            "prompt": "Third enhancement instruction with another angle",
            "focus_area": "Another improvement angle",
            "expected_impact": "Another improvement outcome",
            "priority": "high/medium/low"
        }},
        {{
            "prompt": "Fourth enhancement instruction with final dimension",
            "focus_area": "Final improvement dimension",
            "expected_impact": "Final improvement outcome",
            "priority": "high/medium/low"
        }}
    ]
}}

IMPORTANT: Do NOT include the original text in any of the enhancement prompts. Only provide the improvement instructions."""

        # Use GPT-4.1 as primary model with smart fallbacks
        models_to_try = [
            {
                "name": "chatgpt-4o-latest",  # Latest GPT-4.1
                "params": {
                    "temperature": 0.1,    # Very focused for precise suggestions
                    "max_tokens": 2500,    # Leverage the large output capacity
                    "top_p": 0.95,        # Slight creativity for varied suggestions
                }
            },
            {
                "name": "gpt-4o",  # Strong fallback
                "params": {
                    "temperature": 0.2,
                    "max_tokens": 2000
                }
            }
        ]

        response = None
        model_used = None

        for model_config in models_to_try:
            try:
                model_name = model_config["name"]
                params = model_config["params"]

                logging.info(f"Attempting smart enhancements with {model_name}")

                response = client.chat.completions.create(
                    model=model_name,
                    messages=[
                        {
                            "role": "system",
                            "content": "You are a world-class content strategist and prompt engineer. Your expertise spans writing, coding, business strategy, creative work, and technical documentation. You create enhancement instructions that deliver transformative improvements. Never include the original text in your enhancement instructions."
                        },
                        {
                            "role": "user",
                            "content": enhancement_prompt
                        }
                    ],
                    **params
                )

                model_used = model_name
                logging.info(f"‚úÖ Smart enhancements successful with {model_name}")
                break

            except Exception as e:
                error_msg = str(e)
                logging.warning(f"‚ùå {model_name} failed: {error_msg}")
                continue

        if not response:
            return jsonify({
                'success': False,
                'error': 'All models failed to respond'
            }), 500

        # Enhanced response processing
        ai_response = response.choices[0].message.content.strip()
        logging.info(f"Generated {len(ai_response)} chars with {model_used}")

        try:
            # Parse JSON with enhanced quality
            parsed_data = parse_json_response_enhanced(ai_response)

            # Extract and validate enhancement prompts
            enhancement_prompts = parsed_data.get('enhancement_prompts', [])
            content_analysis = parsed_data.get('content_analysis', {})

            # Ensure high-quality prompts
            validated_prompts = []
            for prompt_data in enhancement_prompts:
                if isinstance(prompt_data, dict) and 'prompt' in prompt_data:
                    prompt_text = prompt_data['prompt'].strip()
                    if len(prompt_text) > 20:
                        validated_prompts.append({
                            "prompt": prompt_text,
                            "focus_area": prompt_data.get('focus_area', 'improvement'),
                            "expected_impact": prompt_data.get('expected_impact', 'Enhanced quality'),
                            "priority": prompt_data.get('priority', 'medium')
                        })

            if len(validated_prompts) == 0:
                raise ValueError("No valid enhancement prompts generated")

            result = {
                'success': True,
                'content_analysis': content_analysis,
                'enhancement_prompts': validated_prompts,
                'model_used': model_used,
                'original_length': len(selected_text),
                'gpt_4_1_used': "gpt-4.1" in model_used
            }

            if credit_result.get('credits_used'):
                result['credits_used'] = credit_result['credits_used']
                result['credits_remaining'] = credit_result.get('remaining')

            return jsonify(result)

        except Exception as e:
            logging.error(f"Response processing failed: {str(e)}")

            # Create premium fallback prompts WITHOUT original text
            fallback_prompts = create_gpt41_fallback_prompts_clean(selected_text)

            result = {
                'success': True,
                'content_analysis': {"type": "Content analyzed", "purpose": "Enhancement ready"},
                'enhancement_prompts': fallback_prompts,
                'model_used': model_used,
                'fallback': True
            }

            if credit_result.get('credits_used'):
                result['credits_used'] = credit_result['credits_used']
                result['credits_remaining'] = credit_result.get('remaining')

            return jsonify(result)

    except Exception as e:
        error_msg = str(e)
        error_type = type(e).__name__

        logging.error(f"=== Smart enhancements error ===")
        logging.error(f"Error type: {error_type}")
        logging.error(f"Error message: {error_msg}")

        return jsonify({
            'success': False,
            'error': 'Failed to generate enhancement suggestions',
            'details': error_msg[:200],
            'error_type': error_type
        }), 500

# Smart Actions helper functions
def build_action_prompt(conversation, platform):
    """Build action-focused prompt for generating actionable follow-up prompts"""

    return f"""
You're helping someone continue their AI conversation by suggesting 3 action-oriented follow-up prompts they can use.

CONVERSATION:
{conversation[:1800]}

Generate 3 follow-up prompts that are:
- Action-oriented and practical (focus on "what to do" rather than "what to know")
- Context-aware and specific to their conversation
- Ready to copy-paste back into the AI chat
- 2-liner prompts that get specific, actionable guidance

Think about what the person would naturally want to DO next based on this conversation:
- If they're learning ‚Üí How to apply/practice it
- If they're problem-solving ‚Üí Next steps to try
- If they're planning ‚Üí How to implement/start
- If they're stuck ‚Üí Specific approaches to attempt

Guidelines:
‚úì Reference specific things mentioned in the conversation
‚úì Focus on implementation and application
‚úì Make prompts specific enough to get actionable responses
‚úì Avoid generic questions - be contextually relevant
‚úì Each prompt should be self-contained and ready to use

JSON format:
{{
    "action_prompts": [
        {{
            "prompt": "Context-specific action-oriented prompt for the AI",
            "focus": "implementation/application/practice",
            "context": "brief description of what this targets"
        }},
        {{
            "prompt": "Second practical follow-up prompt",
            "focus": "planning/strategy/approach",
            "context": "what this helps with"
        }},
        {{
            "prompt": "Third actionable prompt for next steps",
            "focus": "execution/practice/testing",
            "context": "practical outcome"
        }}
    ],
    "analysis": "Brief explanation of how these prompts help take action on the conversation"
}}"""

def extract_action_prompts_from_text(text, conversation=""):
    """Fallback extraction for action prompts when JSON parsing fails"""
    prompts = []
    lines = text.split('\n')

    for line in lines:
        line = line.strip()
        # Look for action-oriented prompt language
        if any(starter in line.lower() for starter in ['help me', 'show me', 'create', 'give me', 'walk me through', 'build', 'plan', 'strategy', 'implement']):
            if len(line) > 40 and len(line) < 500 and '?' in line:
                clean_prompt = line

                # Remove common prefixes
                prefixes = ['"prompt":', 'prompt:', '"', "'", '-', '‚Ä¢', '*', '1.', '2.', '3.']
                for prefix in prefixes:
                    if clean_prompt.startswith(prefix):
                        clean_prompt = clean_prompt[len(prefix):].strip()

                clean_prompt = clean_prompt.rstrip('",\'"').strip()

                if clean_prompt and len(clean_prompt) > 35:
                    prompts.append({
                        "prompt": clean_prompt,
                        "focus": "practical",
                        "context": "actionable guidance"
                    })

    # If no prompts extracted, provide high-quality context-aware defaults
    if len(prompts) == 0:
        prompts = [
            {"prompt": "Help me create an action plan based on our discussion. What are the specific next steps I should take?", "focus": "planning", "context": "next steps"},
            {"prompt": "Give me 3 practical ways to apply what we've discussed. Include specific examples for my situation.", "focus": "application", "context": "practical use"},
            {"prompt": "Walk me through how to get started with this approach. What should I do first and why?", "focus": "getting started", "context": "initial steps"}
        ]

    return prompts[:3]

@app.route('/smart-actions', methods=['POST'])
def smart_actions():
    """Generate smart action-oriented follow-up prompts based on conversation context"""
    try:
        logging.info("=== Smart actions request started ===")

        # ADD CREDIT CHECK
        credit_result = optional_credit_check('smart_actions')
        if not credit_result['success']:
            return jsonify({
                'error': credit_result['message'],
                'credits_required': get_feature_credits('smart_actions')
            }), 402

        # Parse request
        data = request.get_json(force=True)
        conversation = data.get('conversation', '').strip()
        platform = data.get('platform', 'unknown')

        logging.info(f"Conversation length: {len(conversation)}, Platform: {platform}")

        if not conversation:
            return jsonify({'error': 'Conversation content is required'}), 400

        # Build action-focused prompt
        action_prompt = build_action_prompt(conversation, platform)

        # Use reliable models with proper error handling
        models_to_try = [
            {
                "name": "chatgpt-4o-latest",
                "params": {
                    "temperature": 0.3,
                    "max_tokens": 800
                }
            },
            {
                "name": "gpt-3.5-turbo",
                "params": {
                    "temperature": 0.3,
                    "max_tokens": 600
                }
            }
        ]

        response = None
        model_used = None

        # Try models in order
        for model_config in models_to_try:
            try:
                model_name = model_config["name"]
                params = model_config["params"]

                logging.info(f"Trying model: {model_name}")

                response = client.chat.completions.create(
                    model=model_name,
                    messages=[{"role": "user", "content": action_prompt}],
                    **params
                )

                model_used = model_name
                logging.info(f"Successfully used model: {model_name}")
                break

            except Exception as e:
                error_msg = str(e)
                logging.warning(f"Model {model_name} failed: {error_msg}")
                continue

        if not response:
            return jsonify({
                'success': False,
                'error': 'All AI models failed to respond'
            }), 500

        # Parse response
        ai_response = response.choices[0].message.content.strip()
        logging.info(f"AI Response length: {len(ai_response)}")

        try:
            # Parse JSON response
            parsed_response = parse_json_response_enhanced(ai_response)

            # Extract and validate action prompts
            action_prompts = parsed_response.get('action_prompts', [])

            if not isinstance(action_prompts, list) or len(action_prompts) == 0:
                raise ValueError("No valid action prompts found")

            # Process and validate prompts
            validated_prompts = []
            for prompt_item in action_prompts[:3]:  # Limit to 3 prompts
                if isinstance(prompt_item, dict) and 'prompt' in prompt_item:
                    prompt_text = prompt_item['prompt'].strip()
                    if prompt_text and len(prompt_text) > 30:
                        validated_prompts.append({
                            "prompt": prompt_text,
                            "focus": prompt_item.get('focus', 'practical'),
                            "context": prompt_item.get('context', 'general')
                        })

            if len(validated_prompts) == 0:
                raise ValueError("No valid prompts after processing")

            result = {
                'success': True,
                'action_prompts': validated_prompts,
                'analysis': parsed_response.get('analysis', 'Action-oriented prompts generated'),
                'platform': platform,
                'model': model_used
            }

            if credit_result.get('credits_used'):
                result['credits_used'] = credit_result['credits_used']
                result['credits_remaining'] = credit_result.get('remaining')

            return jsonify(result)

        except (json.JSONDecodeError, ValueError) as e:
            logging.error(f"JSON parsing failed: {str(e)}")

            # Fallback extraction
            action_prompts = extract_action_prompts_from_text(ai_response, conversation)

            result = {
                'success': True,
                'action_prompts': action_prompts,
                'analysis': 'Action-oriented prompts generated',
                'platform': platform,
                'model': model_used,
                'fallback': True
            }

            if credit_result.get('credits_used'):
                result['credits_used'] = credit_result['credits_used']
                result['credits_remaining'] = credit_result.get('remaining')

            return jsonify(result)

    except Exception as e:
        error_msg = str(e)
        error_type = type(e).__name__

        logging.error(f"=== Smart actions error ===")
        logging.error(f"Error type: {error_type}")
        logging.error(f"Error message: {error_msg}")

        return jsonify({
            'success': False,
            'error': 'Failed to generate action prompts',
            'details': error_msg[:200],
            'error_type': error_type
        }), 500

# Persona generation functions
def generate_ai_persona_analysis(keyword):
    """Use AI to analyze the role and generate persona components"""

    analysis_prompt = f"""Analyze the role "{keyword}" and provide structured information.

Role to analyze: {keyword}

Please provide a JSON response with the following structure:
{{
    "role_title": "Clean, professional title for this role",
    "experience_level": "junior/mid/senior/expert (inferred from the keyword)",
    "core_skills": [
        "skill 1",
        "skill 2",
        "skill 3",
        "skill 4",
        "skill 5"
    ],
    "communication_style": [
        "communication preference 1",
        "communication preference 2",
        "communication preference 3"
    ],
    "tools_technologies": [
        "tool/technology 1",
        "tool/technology 2"
    ],
    "primary_responsibilities": [
        "responsibility 1",
        "responsibility 2",
        "responsibility 3"
    ],
    "industry_context": "industry or business context",
    "key_phrases": [
        "phrase they would commonly use 1",
        "phrase they would commonly use 2"
    ]
}}

Focus on being specific and practical. If the role includes level indicators (senior, junior, lead, etc.), reflect that in experience_level and adjust skills accordingly."""

    try:
        response = client.chat.completions.create(
            model="chatgpt-4o-latest",
            messages=[
                {
                    "role": "system",
                    "content": "You are an expert HR analyst and role researcher. Provide accurate, practical information about professional roles. Always respond with valid JSON only."
                },
                {
                    "role": "user",
                    "content": analysis_prompt
                }
            ],
            temperature=0.3,
            max_tokens=1000
        )

        ai_response = response.choices[0].message.content.strip()

        # Clean the response - remove markdown code blocks if present
        if "```json" in ai_response:
            ai_response = ai_response.split("```json")[1].split("```")[0]
        elif "```" in ai_response:
            ai_response = ai_response.split("```")[1].split("```")[0]

        # Parse JSON response
        try:
            analysis_data = json.loads(ai_response)
            return analysis_data
        except json.JSONDecodeError as e:
            logging.error(f"JSON parsing failed: {str(e)}")
            logging.error(f"AI Response: {ai_response}")
            return None

    except Exception as e:
        logging.error(f"AI analysis failed: {str(e)}")
        return None

def build_persona_from_ai_analysis(analysis_data, keyword):
    """Build persona template from AI analysis data"""

    if not analysis_data:
        # Fallback if AI analysis fails
        return f"""You are a {keyword} with professional expertise in your field.

Core Competencies:
‚Ä¢ Professional knowledge in {keyword} domain
‚Ä¢ Problem-solving and analytical thinking
‚Ä¢ Communication and collaboration skills
‚Ä¢ Continuous learning and adaptation

Communication Approach:
Provide expert advice with clear reasoning and practical examples. Focus on actionable solutions and best practices.

Response Guidelines:
‚Ä¢ Acknowledge the user's specific question
‚Ä¢ Provide professional-level insights
‚Ä¢ Include practical examples and recommendations
‚Ä¢ Ask follow-up questions to ensure clarity

Remember: You're a knowledgeable {keyword} ready to help solve real problems with your expertise."""

    # Extract data with fallbacks
    role_title = analysis_data.get('role_title', keyword)
    experience_level = analysis_data.get('experience_level', 'professional')
    core_skills = analysis_data.get('core_skills', [])
    communication_style = analysis_data.get('communication_style', [])
    tools_technologies = analysis_data.get('tools_technologies', [])
    primary_responsibilities = analysis_data.get('primary_responsibilities', [])
    industry_context = analysis_data.get('industry_context', '')
    key_phrases = analysis_data.get('key_phrases', [])

    # Build introduction
    intro = f"You are a {experience_level} {role_title}"
    if industry_context:
        intro += f" working in {industry_context}"
    intro += ". You bring specialized expertise and practical experience to solve complex challenges in your field."

    # Build skills section
    skills_section = "Core Competencies:"
    if core_skills:
        for skill in core_skills:
            skills_section += f"\n‚Ä¢ {skill}"
    else:
        skills_section += f"\n‚Ä¢ Professional expertise in {keyword}"

    # Build responsibilities section
    responsibilities_section = ""
    if primary_responsibilities:
        responsibilities_section = "\nPrimary Responsibilities:"
        for responsibility in primary_responsibilities:
            responsibilities_section += f"\n‚Ä¢ {responsibility}"

    # Build communication section
    communication_section = "Communication Approach:"
    if communication_style:
        communication_text = " ".join(communication_style)
        communication_section += f"\n{communication_text}"
    else:
        communication_section += "\nProvide expert advice with clear reasoning and practical examples."

    # Build tools section
    tools_section = ""
    if tools_technologies:
        tools_section = "\nTools & Technologies:"
        for tool in tools_technologies:
            tools_section += f"\n‚Ä¢ {tool}"

    # Build key phrases section
    phrases_section = ""
    if key_phrases:
        phrases_section = "\nKey Phrases You Use:"
        for phrase in key_phrases[:3]:  # Limit to 3 phrases
            phrases_section += f"\n‚Ä¢ \"{phrase}\""

    # Experience level specific additions
    experience_additions = ""
    if experience_level in ['senior', 'expert', 'lead']:
        experience_additions = """
Leadership Qualities:
‚Ä¢ Mentor and guide team members
‚Ä¢ Make strategic decisions and provide direction
‚Ä¢ Drive best practices and innovation
‚Ä¢ Collaborate across departments and stakeholders"""

    # Build final template
    template = f"""{intro}

{skills_section}{responsibilities_section}{experience_additions}

{communication_section}{tools_section}{phrases_section}

Response Guidelines:
‚Ä¢ Start by understanding the specific challenge or question
‚Ä¢ Provide {experience_level}-level insights appropriate to a {role_title}
‚Ä¢ Draw from your professional experience and industry knowledge
‚Ä¢ Include specific examples and actionable recommendations
‚Ä¢ End with clarifying questions to ensure you're addressing core needs

Professional Identity:
"As a {experience_level} {role_title}, I bring {len(core_skills)} key competencies to help solve your challenges effectively."

Remember: You're not just providing information - you're a {experience_level} {role_title} ready to apply your specialized knowledge to solve real problems."""

    return template

def create_dynamic_persona_template(context):
    """Main function to create AI-powered dynamic persona"""
    keyword = context['keyword']

    logging.info(f"Generating AI-powered persona for: {keyword}")

    # Get AI analysis of the role
    analysis_data = generate_ai_persona_analysis(keyword)

    # Build persona template from AI analysis
    persona_template = build_persona_from_ai_analysis(analysis_data, keyword)

    return persona_template

def detect_domain_context(text):
    """Enhanced domain and context detection for persona generation"""
    text_lower = text.lower()

    # More comprehensive domain patterns with better keyword matching
    domain_patterns = {
        'technology': {
            'keywords': ['python', 'javascript', 'react', 'node', 'developer', 'programmer', 'software', 'coding', 'programming', 'ai', 'machine learning', 'data science', 'cybersecurity', 'cloud', 'devops', 'blockchain', 'api', 'database', 'frontend', 'backend', 'fullstack', 'web development', 'mobile development', 'ios', 'android', 'java', 'c++', 'php', 'ruby', 'go', 'rust', 'typescript', 'vue', 'angular'],
            'weight': 1.0
        },
        'business': {
            'keywords': ['marketing', 'sales', 'business', 'strategy', 'management', 'leadership', 'finance', 'consulting', 'entrepreneur', 'startup', 'revenue', 'profit', 'roi', 'kpi', 'analytics', 'growth hacking', 'digital marketing', 'social media', 'seo', 'ppc', 'content marketing', 'email marketing', 'brand', 'branding'],
            'weight': 1.0
        },
        'creative': {
            'keywords': ['design', 'designer', 'art', 'artist', 'creative', 'writing', 'writer', 'content', 'video', 'photography', 'photographer', 'graphics', 'ui', 'ux', 'storytelling', 'music', 'animation', 'illustration', 'copywriter', 'creative director'],
            'weight': 1.0
        },
        'education': {
            'keywords': ['teacher', 'teaching', 'education', 'training', 'trainer', 'learning', 'curriculum', 'academic', 'research', 'researcher', 'science', 'professor', 'tutor', 'course', 'study', 'instructor'],
            'weight': 1.0
        },
        'healthcare': {
            'keywords': ['medical', 'health', 'doctor', 'nurse', 'therapy', 'therapist', 'wellness', 'fitness', 'nutrition', 'psychology', 'psychologist', 'mental health', 'patient', 'healthcare', 'physician'],
            'weight': 1.0
        },
        'legal': {
            'keywords': ['legal', 'law', 'lawyer', 'attorney', 'court', 'contract', 'compliance', 'regulation', 'policy', 'rights', 'paralegal', 'legal counsel'],
            'weight': 1.0
        },
        'finance': {
            'keywords': ['finance', 'financial', 'accountant', 'accounting', 'investment', 'investor', 'banking', 'fintech', 'cryptocurrency', 'trading', 'analyst', 'cfo', 'bookkeeper'],
            'weight': 1.0
        }
    }

    domain_scores = {}

    # Score each domain based on keyword matches
    for domain, config in domain_patterns.items():
        score = 0
        for keyword in config['keywords']:
            if keyword in text_lower:
                score += config['weight']
                # Bonus for exact matches
                if keyword == text_lower.strip():
                    score += 2
        domain_scores[domain] = score

    # Find the domain with highest score
    detected_domain = max(domain_scores, key=domain_scores.get) if max(domain_scores.values()) > 0 else 'general'

    # Detect communication tone
    tone_patterns = {
        'expert': ['senior', 'lead', 'principal', 'expert', 'specialist', 'advanced', 'architect'],
        'casual': ['friendly', 'casual', 'relaxed', 'informal', 'conversational', 'buddy'],
        'creative': ['creative', 'innovative', 'artistic', 'imaginative', 'original', 'visionary'],
        'professional': ['professional', 'business', 'corporate', 'executive', 'formal']  # default
    }

    detected_tone = 'professional'  # default
    for tone, keywords in tone_patterns.items():
        if any(keyword in text_lower for keyword in keywords):
            detected_tone = tone
            break

    return {
        'domain': detected_domain,
        'tone': detected_tone,
        'keyword': text.strip()
    }

@app.route('/generate-persona', methods=['POST'])
def generate_persona():
    """Generate AI-powered dynamic persona template"""
    try:
        # ADD CREDIT CHECK
        credit_result = optional_credit_check('persona_generator')
        if not credit_result['success']:
            return jsonify({
                'error': credit_result['message'],
                'credits_required': get_feature_credits('persona_generator')
            }), 402

        data = request.get_json(force=True)
        keyword = data.get('text', '').strip()

        if not keyword:
            return jsonify({'error': 'Keyword is required'}), 400

        logging.info(f"=== AI Persona Generation Started ===")
        logging.info(f"Input keyword: {keyword}")

        # Detect basic context (keeping existing function for metadata)
        context = detect_domain_context(keyword)
        logging.info(f"Detected domain: {context['domain']}, tone: {context['tone']}")

        # Generate AI-powered persona
        persona_template = create_dynamic_persona_template(context)

        if not persona_template:
            raise Exception("Failed to generate persona template")

        logging.info(f"=== AI Persona Generation Completed ===")

        result = {
            'prompt': persona_template,
            'status': 'success',
            'metadata': {
                'keyword': keyword,
                'domain': context['domain'],
                'tone': context['tone'],
                'mode': 'ai_powered_persona',
                'ai_analyzed': True
            }
        }

        if credit_result.get('credits_used'):
            result['credits_used'] = credit_result['credits_used']
            result['credits_remaining'] = credit_result.get('remaining')

        return jsonify(result)

    except Exception as e:
        logging.error(f"=== AI Persona Generation Failed ===")
        logging.error(f"Error: {str(e)}")
        logging.error(f"Error type: {type(e).__name__}")

        return jsonify({
            'error': 'Failed to generate AI-powered persona',
            'details': str(e),
            'metadata': {
                'fallback_used': True,
                'ai_analyzed': False
            }
        }), 500

# MAILGUN TEST ENDPOINT - ADD THIS
@app.route('/test-mailgun-config', methods=['GET'])
def test_mailgun_config():
    """Test Mailgun configuration"""
    try:
        return jsonify({
            'status': 'success',
            'mailgun_domain': MAILGUN_DOMAIN,
            'api_key_present': bool(MAILGUN_API_KEY),
            'api_key_length': len(MAILGUN_API_KEY) if MAILGUN_API_KEY else 0,
            'frontend_url': FRONTEND_BASE_URL,
            'verification_url': VERIFICATION_BASE_URL,
            'environment_loaded': 'Environment variables loaded successfully'
        })
    except Exception as e:
        return jsonify({
            'status': 'error',
            'error': str(e),
            'message': 'Environment variables not loaded properly'
        }), 500

# ============================================
# MAILGUN EMAIL ENDPOINTS - ADD THESE
# ============================================

@app.route('/send-verification-email', methods=['POST'])
def send_verification_email():
    """Send custom verification email via Mailgun"""
    try:
        data = request.get_json()
        email = data.get('email', '').strip().lower()
        first_name = data.get('firstName', '').strip()

        if not email:
            return jsonify({'error': 'Email is required'}), 400

        print(f"üìß Sending verification email to: {email}")

        # Send via Mailgun
        result = send_verification_email_mailgun(email, first_name)

        if result["success"]:
            return jsonify({
                'success': True,
                'message': 'Verification email sent successfully',
                'provider': 'mailgun',
                'delivered_via': 'Mailgun (95%+ inbox rate)'
            })
        else:
            return jsonify({
                'success': False,
                'message': 'Failed to send verification email',
                'error': result["message"],
                'use_firebase_fallback': True
            }), 500

    except Exception as e:
        print(f"‚ùå Send verification error: {e}")
        return jsonify({
            'error': 'Failed to send verification email',
            'details': str(e)
        }), 500

@app.route('/verify-email', methods=['GET'])
def verify_email():
    """Verify email using token and update Firebase user"""
    try:
        email = request.args.get('email', '').strip().lower()
        token = request.args.get('token', '').strip()

        if not email or not token:
            return f"""
            <html><body style="font-family: Arial; text-align: center; padding: 50px;">
            <h1 style="color: red;">‚ùå Invalid Verification Link</h1>
            <p>The verification link is missing required parameters.</p>
            <a href="{FRONTEND_BASE_URL}/login" style="background: #ffff00; padding: 10px 20px; text-decoration: none; color: black; border-radius: 5px;">Back to Login</a>
            </body></html>
            """

        print(f"üîê Verifying email: {email}")

        # Verify token
        if not verify_token_v2(email, token):
            print(f"‚ùå Invalid or expired token for {email}")
            return f"""
            <html><body style="font-family: Arial; text-align: center; padding: 50px;">
            <h1 style="color: red;">‚ùå Verification Link Expired</h1>
            <p>This verification link has expired. Please request a new one.</p>
            <a href="{FRONTEND_BASE_URL}/login" style="background: #ffff00; padding: 10px 20px; text-decoration: none; color: black; border-radius: 5px;">Back to Login</a>
            </body></html>
            """

        # Update Firebase user as verified
        if FIREBASE_ENABLED:
            try:
                # Get user by email
                user = auth.get_user_by_email(email)

                # Update user as verified
                auth.update_user(
                    user.uid,
                    email_verified=True
                )

                print(f"‚úÖ Email verified for user: {email}")

                # Success page
                return f"""
                <html><body style="font-family: Arial; text-align: center; padding: 50px;">
                <h1 style="color: green;">‚úÖ Email Verified Successfully!</h1>
                <p>Great! Your email address has been verified. You can now log in to your Solthron account.</p>
                <div style="margin: 30px 0;">
                    <h3>üéØ What's Next?</h3>
                    <ol style="text-align: left; display: inline-block;">
                        <li>Log in to your account</li>
                        <li>Install the Chrome extension</li>
                        <li>Start optimizing your AI prompts</li>
                    </ol>
                </div>
                <a href="{FRONTEND_BASE_URL}/login" style="background: #ffff00; padding: 15px 30px; text-decoration: none; color: black; border-radius: 5px; font-weight: bold; margin: 10px;">Login Now</a>
                <p style="margin-top: 30px; color: #666; font-size: 14px;">Redirecting to login in 5 seconds...</p>
                <script>setTimeout(function(){{ window.location.href = '{FRONTEND_BASE_URL}/login'; }}, 5000);</script>
                </body></html>
                """

            except auth.UserNotFoundError:
                print(f"‚ùå User not found: {email}")
                return f"""
                <html><body style="font-family: Arial; text-align: center; padding: 50px;">
                <h1 style="color: red;">‚ùå User Not Found</h1>
                <p>No account found with this email address.</p>
                <a href="{FRONTEND_BASE_URL}/signup" style="background: #ffff00; padding: 10px 20px; text-decoration: none; color: black; border-radius: 5px;">Create Account</a>
                </body></html>
                """
            except Exception as firebase_error:
                print(f"‚ùå Firebase error: {firebase_error}")
                return f"""
                <html><body style="font-family: Arial; text-align: center; padding: 50px;">
                <h1 style="color: red;">‚ùå Verification Error</h1>
                <p>There was an issue verifying your account. Please try again or contact support.</p>
                <a href="{FRONTEND_BASE_URL}/login" style="background: #ffff00; padding: 10px 20px; text-decoration: none; color: black; border-radius: 5px;">Back to Login</a>
                </body></html>
                """
        else:
            return f"""
            <html><body style="font-family: Arial; text-align: center; padding: 50px;">
            <h1 style="color: red;">‚ùå Service Unavailable</h1>
            <p>Email verification service is temporarily unavailable.</p>
            <a href="{FRONTEND_BASE_URL}/login" style="background: #ffff00; padding: 10px 20px; text-decoration: none; color: black; border-radius: 5px;">Back to Login</a>
            </body></html>
            """

    except Exception as e:
        print(f"‚ùå Verification error: {e}")
        return f"""
        <html><body style="font-family: Arial; text-align: center; padding: 50px;">
        <h1 style="color: red;">‚ùå Server Error</h1>
        <p>An unexpected error occurred during verification.</p>
        <a href="{FRONTEND_BASE_URL}/login" style="background: #ffff00; padding: 10px 20px; text-decoration: none; color: black; border-radius: 5px;">Back to Login</a>
        </body></html>
        """

@app.route('/analyze-context', methods=['POST'])
def analyze_context():
    """Analyze user's input context for auto suggestion mode"""
    try:
        # ADD CREDIT CHECK
        credit_result = optional_credit_check('auto_suggestion')
        if not credit_result['success']:
            return jsonify({
                'error': credit_result['message'],
                'credits_required': get_feature_credits('auto_suggestion')
            }), 402

        data = request.get_json(force=True)
        input_text = data.get('input_text', '').strip()
        platform = data.get('platform', 'unknown')
        timestamp = data.get('timestamp', 0)

        if not input_text:
            return jsonify({'error': 'Input text is required'}), 400

        print(f"ü§ñ Analyzing context for: {input_text[:50]}...")

        # Analyze the user's input context
        analysis_result = analyze_user_context_with_ai(input_text, platform)

        result = {
            'success': True,
            'warm_message': analysis_result['warm_message'],
            'detected_context': analysis_result['detected_context'],
            'confidence': analysis_result['confidence'],
            'platform': platform,
            'analysis_timestamp': timestamp
        }

        if credit_result.get('credits_used'):
            result['credits_used'] = credit_result['credits_used']
            result['credits_remaining'] = credit_result.get('remaining')

        print(f"‚úÖ Context analysis complete: {analysis_result['detected_context']}")
        return jsonify(result)

    except Exception as e:
        print(f"‚ùå Context analysis error: {e}")
        return jsonify({
            'error': 'Failed to analyze context',
            'details': str(e)
        }), 500

@app.route('/synthesize-conversation', methods=['POST'])
def synthesize_conversation():
    """Synthesize multiple conversation inputs into a better prompt"""
    try:
        # ADD CREDIT CHECK
        credit_result = optional_credit_check('smart_enhancements')
        if not credit_result['success']:
            return jsonify({
                'error': credit_result['message'],
                'credits_required': get_feature_credits('smart_enhancements')
            }), 402

        data = request.get_json()
        inputs = data.get('inputs', [])
        platform = data.get('platform', 'unknown')
        session_id = data.get('sessionId', '')

        if not inputs or len(inputs) < 2:
            return jsonify({'error': 'At least 2 inputs required for synthesis'}), 400

        print(f"üîÑ Synthesizing {len(inputs)} inputs for session: {session_id}")

        # Build synthesis prompt
        input_texts = [inp.get('text', '') for inp in inputs]
        conversation_flow = '\n'.join([f"Input {i+1}: {text}" for i, text in enumerate(input_texts)])

        synthesis_prompt = f"""You are an expert prompt engineer creating "practical magic" - prompts that give users helpful details they wouldn't think of, without overwhelming them.

User's conversation flow:
{conversation_flow}

ANALYSIS FRAMEWORK:
1. What type of work is in progress? (writing, coding, planning, etc.)
2. What's the user's apparent skill level? (beginner asking for simple things vs advanced requests)
3. What practical improvements would genuinely help but they wouldn't think to ask for?

PRACTICAL MAGIC PRINCIPLES:
‚úÖ Add helpful specifics they wouldn't consider
‚úÖ Include real-world examples and use cases
‚úÖ Suggest common pitfalls to avoid
‚úÖ Add user-focused improvements that matter
‚úÖ Keep it practical and actionable
‚úÖ Create an OPTIMIZED PROMPT, not an answer
‚úÖ Refine their request to be more specific and effective
‚úÖ Help them ask better questions, don't provide solutions
‚ùå No overwhelming technical jargon
‚ùå No over-engineering or complex frameworks
‚ùå Don't change their core intent

EXAMPLES BY DOMAIN:

WRITING (Blog/Content):
‚ùå Basic: "Make the blog more engaging"
‚ùå Overwhelming: "Implement AIDA framework with conversion funnels and behavioral psychology"
‚úÖ Practical Magic: "Add personal anecdotes, include specific examples readers can relate to, address common objections people have about this topic, and end with actionable next steps"

CODING:
‚ùå Basic: "Add error handling to the component"
‚ùå Overwhelming: "Implement enterprise architecture with dependency injection and observer patterns"
‚úÖ Practical Magic: "Add helpful error messages users can understand, loading states so users know something's happening, and simple validation to prevent common mistakes"

CREATIVE (Poems/Stories):
‚ùå Basic: "Make the character description more detailed"
‚ùå Overwhelming: "Apply literary theory with metaphysical conceits and postmodern narrative techniques"
‚úÖ Practical Magic: "Add sensory details like sounds and textures, include emotional reactions that make readers connect with the character, and create a vivid setting that feels real"

BUSINESS:
‚ùå Basic: "Improve the marketing plan"
‚ùå Overwhelming: "Create omnichannel attribution models with predictive analytics and behavioral segmentation"
‚úÖ Practical Magic: "Include specific budget numbers, realistic timelines with milestones, ways to measure if it's working, and backup plans if the first approach doesn't work"

YOUR TASK:
Create ONE continuation prompt that enhances existing work with practical details that create an "aha moment" - things that are genuinely helpful but the user wouldn't think to ask for and just give the prompt as the output - dont ask a question - the prompt will be directly copy pasted by the user.

Take their basic request and make it more detailed and effective while keeping the same intent, refer to the Practical magical example for the length of the prompt

Enhanced continuation prompt:"""

        response = client.chat.completions.create(
            model="chatgpt-4o-latest",
            messages=[
                {
                    "role": "system",
                    "content": "You are an expert at creating 'practical magic' prompts - enhancements that give users helpful details they wouldn't think of, without overwhelming them. Focus on genuinely useful improvements that create 'aha moments'."
                },
                {
                    "role": "user",
                    "content": synthesis_prompt
                }
            ],
            temperature=0.3,
            max_tokens=800
        )

        synthesized_prompt = response.choices[0].message.content.strip()

        # Clean up the response - remove any meta text
        if synthesized_prompt.startswith("Optimized continuation prompt:"):
            synthesized_prompt = synthesized_prompt.replace("Optimized continuation prompt:", "").strip()
        if synthesized_prompt.startswith("Here's"):
            lines = synthesized_prompt.split('\n')
            synthesized_prompt = '\n'.join(lines[1:]).strip()

        result = {
            'success': True,
            'synthesized_prompt': synthesized_prompt,
            'input_count': len(inputs),
            'session_id': session_id,
            'platform': platform
        }

        if credit_result.get('credits_used'):
            result['credits_used'] = credit_result['credits_used']
            result['credits_remaining'] = credit_result.get('remaining')

        print(f"‚úÖ Synthesis complete for session: {session_id}")
        return jsonify(result)

    except Exception as e:
        print(f"‚ùå Synthesis error: {e}")
        return jsonify({
            'error': 'Failed to synthesize conversation',
            'details': str(e)
        }), 500

@app.route('/analyze-intervention', methods=['POST'])
def analyze_intervention():
    """Analyze conversation progression for personalized intervention message"""
    try:
        # ADD CREDIT CHECK (same as auto suggestion - 3 credits)
        credit_result = optional_credit_check('auto_suggestion')
        if not credit_result['success']:
            return jsonify({
                'error': credit_result['message'],
                'credits_required': get_feature_credits('auto_suggestion')
            }), 402

        data = request.get_json()
        inputs = data.get('inputs', [])
        platform = data.get('platform', 'unknown')

        if not inputs or len(inputs) < 2:
            return jsonify({'error': 'At least 2 inputs required for intervention analysis'}), 400

        print(f"üîç Analyzing intervention for {len(inputs)} inputs...")

        # Get the last 2-3 inputs for better context
        recent_inputs = inputs[-3:] if len(inputs) >= 3 else inputs[-2:]
        input_1 = recent_inputs[0].get('text', '')
        input_2 = recent_inputs[1].get('text', '')
        input_3 = recent_inputs[2].get('text', '') if len(recent_inputs) >= 3 else ''

        analysis_prompt = f"""Analyze this conversation progression to create a personalized intervention message.

Input 1 (Original): "{input_1}"
Input 2 (Modification): "{input_2}"
{f'Input 3 (Additional): "{input_3}"' if input_3 else ''}

The user made an original request, then tried to refine/modify it{' multiple times' if input_3 else ''}. I need to show them a helpful popup.

Create a short, personalized message (max 12 words) that:
1. Shows I understand their original intent AND their modification
2. Offers to help them craft a better prompt
3. Uses the specific topics/concepts they mentioned
4. Sounds encouraging and helpful

Examples of good intervention messages:
- "I see you want a shorter crypto blog. Let me help!"
- "Marketing strategy with social media focus - I'll craft it better!"
- "React component but simpler - let me optimize that prompt!"
- "Professional email that's more casual - I can combine these!"
- "Crypto blog that's shorter + includes dogecoin - let me merge these!"
- "Marketing plan with budget constraints + social focus - I'll optimize!"

JSON Format:
{{
    "intervention_message": "personalized message here",
    "detected_intent": "what they're trying to achieve",
    "detected_modification": "how they're trying to change it",
    "confidence": 0.0-1.0
}}

Keep the intervention_message under 12 words and make it specific to their actual requests."""

        response = client.chat.completions.create(
            model="chatgpt-4o-latest",
            messages=[
                {
                    "role": "system",
                    "content": "You are an intelligent conversation assistant that creates personalized, encouraging intervention messages. Always respond with valid JSON only."
                },
                {
                    "role": "user",
                    "content": analysis_prompt
                }
            ],
            temperature=0.3,
            max_tokens=300
        )

        ai_response = response.choices[0].message.content.strip()

        # Clean and parse JSON response
        if "```json" in ai_response:
            ai_response = ai_response.split("```json")[1].split("```")[0]
        elif "```" in ai_response:
            ai_response = ai_response.split("```")[1].split("```")[0]

        # Find JSON boundaries
        start_idx = ai_response.find('{')
        end_idx = ai_response.rfind('}') + 1

        if start_idx != -1 and end_idx > start_idx:
            json_str = ai_response[start_idx:end_idx]
            analysis_data = json.loads(json_str)

            result = {
                'success': True,
                'intervention_message': analysis_data.get('intervention_message', 'I can help craft a better prompt combining everything!'),
                'detected_intent': analysis_data.get('detected_intent', 'general'),
                'detected_modification': analysis_data.get('detected_modification', 'refinement'),
                'confidence': float(analysis_data.get('confidence', 0.8)),
                'platform': platform,
                'input_count': len(inputs)
            }

            if credit_result.get('credits_used'):
                result['credits_used'] = credit_result['credits_used']
                result['credits_remaining'] = credit_result.get('remaining')

            print(f"‚úÖ Intervention analysis complete: {result['intervention_message']}")
            return jsonify(result)

        else:
            # Fallback if JSON parsing fails
            result = {
                'success': True,
                'intervention_message': 'I can help craft a better prompt combining everything!',
                'detected_intent': 'general',
                'detected_modification': 'refinement',
                'confidence': 0.5,
                'platform': platform,
                'input_count': len(inputs)
            }

            if credit_result.get('credits_used'):
                result['credits_used'] = credit_result['credits_used']
                result['credits_remaining'] = credit_result.get('remaining')

            return jsonify(result)

    except Exception as e:
        print(f"‚ùå Intervention analysis error: {e}")
        return jsonify({
            'error': 'Failed to analyze intervention',
            'details': str(e)
        }), 500

@app.route('/analyze-motivation', methods=['POST'])
def analyze_motivation():
    """Generate personalized motivational message for 5th prompt"""
    try:
        # ADD CREDIT CHECK (same as auto suggestion - 3 credits)
        credit_result = optional_credit_check('auto_suggestion')
        if not credit_result['success']:
            return jsonify({
                'error': credit_result['message'],
                'credits_required': get_feature_credits('auto_suggestion')
            }), 402

        data = request.get_json()
        inputs = data.get('inputs', [])
        platform = data.get('platform', 'unknown')

        if not inputs or len(inputs) < 5:
            return jsonify({'error': 'Need at least 5 inputs for motivational analysis'}), 400

        print(f"üí™ Analyzing motivation for {len(inputs)} inputs...")

        # Get the user's journey context
        input_texts = [inp.get('text', '') for inp in inputs]
        conversation_context = ' | '.join(input_texts)

        motivation_prompt = f"""You are an encouraging AI assistant analyzing a user's conversation journey to provide personalized motivation.

User's conversation journey (5 prompts):
{conversation_context}

Create a short, personalized motivational message (max 15 words) that:
1. Shows you understand their specific topic/project
2. Acknowledges their progress and persistence
3. Sounds genuinely encouraging and supportive
4. References their actual work/topic specifically
5. Feels personal and warm

Examples of good motivational messages:
- "Your marketing strategy is really taking shape - the research depth shows!"
- "This React component is getting more sophisticated with each iteration!"
- "Your crypto blog concept is becoming really compelling and unique!"
- "The way you're refining this business plan shows real strategic thinking!"

JSON Format:
{{
    "motivational_message": "personalized encouraging message here",
    "detected_topic": "what they're working on",
    "progress_observed": "what progress you noticed",
    "confidence": 0.0-1.0
}}

Keep the motivational_message under 15 words and make it specific to their actual work."""

        response = client.chat.completions.create(
            model="chatgpt-4o-latest",
            messages=[
                {
                    "role": "system",
                    "content": "You are a supportive AI coach that provides personalized encouragement. Always respond with valid JSON only."
                },
                {
                    "role": "user",
                    "content": motivation_prompt
                }
            ],
            temperature=0.4,
            max_tokens=300
        )

        ai_response = response.choices[0].message.content.strip()

        # Clean and parse JSON response
        if "```json" in ai_response:
            ai_response = ai_response.split("```json")[1].split("```")[0]
        elif "```" in ai_response:
            ai_response = ai_response.split("```")[1].split("```")[0]

        # Find JSON boundaries
        start_idx = ai_response.find('{')
        end_idx = ai_response.rfind('}') + 1

        if start_idx != -1 and end_idx > start_idx:
            json_str = ai_response[start_idx:end_idx]
            analysis_data = json.loads(json_str)

            result = {
                'success': True,
                'motivational_message': analysis_data.get('motivational_message', 'You\'re making excellent progress - keep going!'),
                'detected_topic': analysis_data.get('detected_topic', 'your project'),
                'progress_observed': analysis_data.get('progress_observed', 'steady improvement'),
                'confidence': float(analysis_data.get('confidence', 0.8)),
                'platform': platform,
                'input_count': len(inputs)
            }

            if credit_result.get('credits_used'):
                result['credits_used'] = credit_result['credits_used']
                result['credits_remaining'] = credit_result.get('remaining')

            print(f"‚úÖ Motivational analysis complete: {result['motivational_message']}")
            return jsonify(result)

        else:
            # Fallback if JSON parsing fails
            result = {
                'success': True,
                'motivational_message': 'You\'re making excellent progress with your conversation!',
                'detected_topic': 'your project',
                'progress_observed': 'steady improvement',
                'confidence': 0.5,
                'platform': platform,
                'input_count': len(inputs)
            }

            if credit_result.get('credits_used'):
                result['credits_used'] = credit_result['credits_used']
                result['credits_remaining'] = credit_result.get('remaining')

            return jsonify(result)

    except Exception as e:
        print(f"‚ùå Motivational analysis error: {e}")
        return jsonify({
            'error': 'Failed to analyze motivation',
            'details': str(e)
        }), 500

@app.route('/resend-verification', methods=['POST'])
def resend_verification():
    """Resend verification email"""
    try:
        data = request.get_json()
        email = data.get('email', '').strip().lower()
        first_name = data.get('firstName', '').strip()

        if not email:
            return jsonify({'error': 'Email is required'}), 400

        print(f"üîÑ Resending verification email to: {email}")

        # Send verification email
        result = send_verification_email_mailgun(email, first_name)

        if result["success"]:
            return jsonify({
                'success': True,
                'message': 'Verification email resent successfully'
            })
        else:
            return jsonify({
                'success': False,
                'message': 'Failed to resend verification email',
                'use_firebase_fallback': True
            }), 500

    except Exception as e:
        print(f"‚ùå Resend verification error: {e}")
        return jsonify({
            'error': 'Failed to resend verification email',
            'details': str(e)
        }), 500

@app.route('/summarize-ai-responses', methods=['POST'])
def summarize_ai_responses():
    """Summarize AI responses for context memory"""
    try:
        # ADD CREDIT CHECK
        credit_result = optional_credit_check('auto_suggestion')  # 3 credits like other auto features
        if not credit_result['success']:
            return jsonify({
                'error': credit_result['message'],
                'credits_required': get_feature_credits('auto_suggestion')
            }), 402

        data = request.get_json()
        responses = data.get('responses', [])
        platform = data.get('platform', 'unknown')

        if not responses:
            return jsonify({'error': 'No responses provided'}), 400

        print(f"üìù Summarizing {len(responses)} AI responses for platform: {platform}")

        # Create summarization prompt
        responses_text = ""
        for i, response in enumerate(responses):
            responses_text += f"Response {i+1}:\n{response.get('content', '')}\n\n"

        summarization_prompt = f"""You are an expert at creating concise, informative summaries of AI responses for conversation context.

AI Responses to Summarize:
{responses_text}

Create brief but informative summaries (2-3 sentences each) that capture:
- Main points or conclusions
- Key recommendations or advice given
- Important facts, numbers, or code mentioned
- Overall direction of the response

Return as JSON:
{{
    "summaries": [
        "Brief summary of response 1...",
        "Brief summary of response 2...",
        ...
    ]
}}"""

        response = client.chat.completions.create(
            model="chatgpt-4o-latest",
            messages=[
                {
                    "role": "system",
                    "content": "You are an expert at creating concise summaries. Always respond with valid JSON only."
                },
                {
                    "role": "user",
                    "content": summarization_prompt
                }
            ],
            temperature=0.3,
            max_tokens=800
        )

        ai_response = response.choices[0].message.content.strip()

        # Parse JSON response
        try:
            if "```json" in ai_response:
                ai_response = ai_response.split("```json")[1].split("```")[0]
            elif "```" in ai_response:
                ai_response = ai_response.split("```")[1].split("```")[0]

            start_idx = ai_response.find('{')
            end_idx = ai_response.rfind('}') + 1

            if start_idx != -1 and end_idx > start_idx:
                json_str = ai_response[start_idx:end_idx]
                summary_data = json.loads(json_str)

                result = {
                    'success': True,
                    'summaries': summary_data.get('summaries', []),
                    'platform': platform,
                    'count': len(responses)
                }

                if credit_result.get('credits_used'):
                    result['credits_used'] = credit_result['credits_used']
                    result['credits_remaining'] = credit_result.get('remaining')

                print(f"‚úÖ Successfully summarized {len(result['summaries'])} responses")
                return jsonify(result)

        except json.JSONDecodeError as e:
            print(f"‚ùå JSON parsing failed: {e}")
            # Fallback: create simple summaries
            fallback_summaries = []
            for response in responses:
                content = response.get('content', '')
                if len(content) > 200:
                    summary = content[:200] + "..."
                else:
                    summary = content
                fallback_summaries.append(summary)

            result = {
                'success': True,
                'summaries': fallback_summaries,
                'platform': platform,
                'count': len(responses),
                'fallback': True
            }

            if credit_result.get('credits_used'):
                result['credits_used'] = credit_result['credits_used']
                result['credits_remaining'] = credit_result.get('remaining')

            return jsonify(result)

    except Exception as e:
        print(f"‚ùå Summarization error: {e}")
        return jsonify({
            'error': 'Failed to summarize AI responses',
            'details': str(e)
        }), 500

@app.route('/generate-context-story', methods=['POST'])
def generate_context_story():
    """Generate comprehensive context story from conversation log"""
    try:
        # ADD CREDIT CHECK
        credit_result = optional_credit_check('auto_suggestion')  # 3 credits
        if not credit_result['success']:
            return jsonify({
                'error': credit_result['message'],
                'credits_required': get_feature_credits('auto_suggestion')
            }), 402

        data = request.get_json()
        conversation_log = data.get('conversationLog', [])
        platform = data.get('platform', 'unknown')
        session_id = data.get('sessionId', 'unknown')
        session_duration = data.get('sessionDuration', 0)

        if not conversation_log or len(conversation_log) < 2:
            return jsonify({'error': 'Insufficient conversation data for story generation'}), 400

        print(f"üìñ Generating context story from {len(conversation_log)} conversation entries")

        # Format conversation for analysis
        conversation_text = ""
        user_inputs = []
        ai_responses = []

        for entry in conversation_log:
            if entry.get('type') == 'user':
                conversation_text += f"User: {entry.get('content', '')}\n\n"
                user_inputs.append(entry.get('content', ''))
            elif entry.get('type') == 'ai':
                conversation_text += f"AI: {entry.get('content', '')}\n\n"
                ai_responses.append(entry.get('content', ''))

        # Calculate session info
        duration_minutes = round(session_duration / (1000 * 60), 1)

        story_generation_prompt = f"""You are an expert at creating comprehensive context stories from AI conversations.

Conversation Details:
- Platform: {platform}
- Duration: {duration_minutes} minutes
- Total exchanges: {len(conversation_log)//2} (approx)
- Session ID: {session_id}

Full Conversation:
{conversation_text}

Create a detailed context story that captures:

1. **Objective**: What was the user trying to accomplish?
2. **Journey**: How did the conversation progress step by step?
3. **Key Discoveries**: Important insights, solutions, or breakthroughs
4. **Current Status**: Where things stand at the end
5. **Context for Future**: Essential background info for continuing this work
6. **Topic/Theme**: Extract the main topic for the title

Format as a structured story that someone could use to continue this conversation in a future session.

Return as JSON:
{{
    "topic": "Extracted main topic (5-8 words max)",
    "story": "Detailed context story in structured format",
    "objective": "What user was trying to accomplish",
    "key_insights": ["insight 1", "insight 2", "insight 3"],
    "next_steps": ["suggested next step 1", "suggested next step 2"],
    "session_summary": {{
        "platform": "{platform}",
        "duration_minutes": {duration_minutes},
        "exchanges": {len(conversation_log)//2}
    }}
}}"""

        response = client.chat.completions.create(
            model="chatgpt-4o-latest",
            messages=[
                {
                    "role": "system",
                    "content": "You are an expert at analyzing conversations and creating detailed context stories. Always respond with valid JSON only."
                },
                {
                    "role": "user",
                    "content": story_generation_prompt
                }
            ],
            temperature=0.3,
            max_tokens=1500
        )

        ai_response = response.choices[0].message.content.strip()

        # Parse JSON response
        try:
            if "```json" in ai_response:
                ai_response = ai_response.split("```json")[1].split("```")[0]
            elif "```" in ai_response:
                ai_response = ai_response.split("```")[1].split("```")[0]

            start_idx = ai_response.find('{')
            end_idx = ai_response.rfind('}') + 1

            if start_idx != -1 and end_idx > start_idx:
                json_str = ai_response[start_idx:end_idx]
                story_data = json.loads(json_str)

                # Format the final story with metadata
                formatted_story = f"""üìñ CONTEXT STORY: {story_data.get('topic', 'AI Conversation')}

üéØ OBJECTIVE:
{story_data.get('objective', 'Not specified')}

üìù CONVERSATION JOURNEY:
{story_data.get('story', 'Story generation failed')}

üí° KEY INSIGHTS:
"""

                insights = story_data.get('key_insights', [])
                for i, insight in enumerate(insights, 1):
                    formatted_story += f"{i}. {insight}\n"

                formatted_story += f"""
üöÄ SUGGESTED NEXT STEPS:
"""

                next_steps = story_data.get('next_steps', [])
                for i, step in enumerate(next_steps, 1):
                    formatted_story += f"{i}. {step}\n"

                session_info = story_data.get('session_summary', {})
                formatted_story += f"""
üìä SESSION INFO:
- Platform: {session_info.get('platform', platform)}
- Duration: {session_info.get('duration_minutes', duration_minutes)} minutes
- Exchanges: {session_info.get('exchanges', len(conversation_log)//2)}
- Generated: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M')}

üíº HOW TO USE THIS CONTEXT:
Copy this entire context and paste it at the beginning of your next AI conversation to continue where you left off."""

                result = {
                    'success': True,
                    'story': formatted_story,
                    'topic': story_data.get('topic', f'Context Story - {datetime.datetime.now().strftime("%m/%d")}'),
                    'raw_data': story_data,
                    'session_info': {
                        'platform': platform,
                        'duration_minutes': duration_minutes,
                        'total_entries': len(conversation_log)
                    }
                }

                if credit_result.get('credits_used'):
                    result['credits_used'] = credit_result['credits_used']
                    result['credits_remaining'] = credit_result.get('remaining')

                print(f"‚úÖ Context story generated successfully: {story_data.get('topic', 'Unknown Topic')}")
                return jsonify(result)

        except json.JSONDecodeError as e:
            print(f"‚ùå JSON parsing failed: {e}")

            # Fallback: create basic story
            fallback_story = f"""üìñ CONTEXT STORY: AI Conversation Summary

üéØ OBJECTIVE:
The user engaged in a {duration_minutes}-minute conversation on {platform}.

üìù CONVERSATION SUMMARY:
User started with: "{user_inputs[0] if user_inputs else 'Unknown'}"

The conversation involved {len(conversation_log)//2} exchanges covering various topics and questions.

üí° KEY POINTS:
- Platform: {platform}
- Duration: {duration_minutes} minutes
- Total exchanges: {len(conversation_log)//2}

üìä SESSION INFO:
- Generated: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M')}
- Session ID: {session_id}

üíº HOW TO USE THIS CONTEXT:
Copy this context and reference it in future conversations to maintain continuity."""

            result = {
                'success': True,
                'story': fallback_story,
                'topic': f'Context Story - {datetime.datetime.now().strftime("%m/%d")}',
                'fallback': True,
                'session_info': {
                    'platform': platform,
                    'duration_minutes': duration_minutes,
                    'total_entries': len(conversation_log)
                }
            }

            if credit_result.get('credits_used'):
                result['credits_used'] = credit_result['credits_used']
                result['credits_remaining'] = credit_result.get('remaining')

            return jsonify(result)

    except Exception as e:
        print(f"‚ùå Context story generation error: {e}")
        return jsonify({
            'error': 'Failed to generate context story',
            'details': str(e)
        }), 500

# ========== COPY PASTE THIS BEFORE: if __name__ == '__main__': ==========

@app.route('/generate-context-summary', methods=['POST'])
def generate_context_summary():
    """Generate comprehensive context summary of the entire conversation"""
    try:
        logging.info("=== Context summary request started ===")

        # ADD CREDIT CHECK
        credit_result = optional_credit_check('smart_enhancements')  # Using same credits as smart enhancements
        if not credit_result['success']:
            return jsonify({
                'error': credit_result['message'],
                'credits_required': get_feature_credits('smart_enhancements')
            }), 402

        # Parse request
        data = request.get_json(force=True)
        conversation = data.get('conversation', '').strip()
        platform = data.get('platform', 'unknown')

        logging.info(f"Conversation length: {len(conversation)}, Platform: {platform}")

        if not conversation:
            return jsonify({'error': 'Conversation content is required'}), 400

        # Build context summary prompt
        summary_prompt = f"""You are an expert conversation analyst. Analyze this entire conversation and create a comprehensive context summary.

CONVERSATION TO ANALYZE:
{conversation[:2500]}

Create a structured summary that captures:

1. **CONVERSATION OVERVIEW**
   - Main purpose/goal of the conversation
   - Overall conversation type (planning, problem-solving, learning, etc.)
   - Key participants and their roles

2. **TOPICS DISCUSSED**
   - Primary topics covered
   - Secondary topics or tangents
   - Topic progression/flow

3. **DECISIONS & CONCLUSIONS**
   - Key decisions made
   - Conclusions reached
   - Agreements or consensus points

4. **ACTION ITEMS & OUTCOMES**
   - Specific actions planned or taken
   - Deliverables mentioned
   - Next steps identified

5. **KEY INSIGHTS & LEARNINGS**
   - Important insights discovered
   - Problems solved
   - Knowledge gained

6. **CONVERSATION DYNAMICS**
   - Communication style and tone
   - Level of engagement
   - Collaboration patterns

Provide the summary in JSON format:
{{
    "overview": {{
        "purpose": "Main purpose of conversation",
        "type": "conversation type",
        "duration_estimate": "estimated conversation length"
    }},
    "topics": [
        {{
            "topic": "topic name",
            "importance": "high/medium/low",
            "discussion_depth": "surface/moderate/deep"
        }}
    ],
    "decisions": [
        {{
            "decision": "decision made",
            "rationale": "reasoning behind decision",
            "impact": "expected impact"
        }}
    ],
    "action_items": [
        {{
            "action": "specific action",
            "priority": "high/medium/low",
            "timeline": "when to complete"
        }}
    ],
    "insights": [
        {{
            "insight": "key insight discovered",
            "significance": "why this matters",
            "application": "how to apply this"
        }}
    ],
    "summary_text": "2-3 paragraph comprehensive summary of the entire conversation",
    "key_takeaways": [
        "Most important takeaway 1",
        "Most important takeaway 2",
        "Most important takeaway 3"
    ]
}}

Focus on being comprehensive yet concise. Capture the essence of what happened in this conversation."""

        # Use reliable models with proper error handling
        models_to_try = [
            {
                "name": "chatgpt-4o-latest",
                "params": {
                    "temperature": 0.2,
                    "max_tokens": 1500
                }
            },
            {
                "name": "gpt-4o",
                "params": {
                    "temperature": 0.2,
                    "max_tokens": 1200
                }
            }
        ]

        response = None
        model_used = None

        # Try models in order
        for model_config in models_to_try:
            try:
                model_name = model_config["name"]
                params = model_config["params"]

                logging.info(f"Trying model: {model_name}")

                response = client.chat.completions.create(
                    model=model_name,
                    messages=[
                        {
                            "role": "system",
                            "content": "You are an expert conversation analyst who creates comprehensive, structured summaries. Always respond with valid JSON only."
                        },
                        {
                            "role": "user",
                            "content": summary_prompt
                        }
                    ],
                    **params
                )

                model_used = model_name
                logging.info(f"Successfully used model: {model_name}")
                break

            except Exception as e:
                error_msg = str(e)
                logging.warning(f"Model {model_name} failed: {error_msg}")
                continue

        if not response:
            return jsonify({
                'success': False,
                'error': 'All AI models failed to respond'
            }), 500

        # Parse response
        ai_response = response.choices[0].message.content.strip()
        logging.info(f"AI Response length: {len(ai_response)}")

        try:
            # Parse JSON response
            parsed_response = parse_json_response_enhanced(ai_response)

            # Validate required fields
            required_fields = ['overview', 'topics', 'decisions', 'action_items', 'insights', 'summary_text', 'key_takeaways']
            for field in required_fields:
                if field not in parsed_response:
                    parsed_response[field] = []

            # Ensure overview is a dict
            if not isinstance(parsed_response.get('overview'), dict):
                parsed_response['overview'] = {
                    "purpose": "Conversation analysis",
                    "type": "general discussion",
                    "duration_estimate": "unknown"
                }

            # Ensure summary_text exists
            if not parsed_response.get('summary_text'):
                parsed_response['summary_text'] = "This conversation covered various topics and included meaningful discussion between participants."

            result = {
                'success': True,
                'summary': parsed_response,
                'platform': platform,
                'model': model_used,
                'conversation_length': len(conversation)
            }

            if credit_result.get('credits_used'):
                result['credits_used'] = credit_result['credits_used']
                result['credits_remaining'] = credit_result.get('remaining')

            return jsonify(result)

        except (json.JSONDecodeError, ValueError) as e:
            logging.error(f"JSON parsing failed: {str(e)}")

            # Fallback summary if JSON parsing fails
            fallback_summary = {
                "overview": {
                    "purpose": "Conversation analysis",
                    "type": "general discussion",
                    "duration_estimate": "moderate"
                },
                "topics": [
                    {"topic": "Main discussion points", "importance": "high", "discussion_depth": "moderate"}
                ],
                "decisions": [
                    {"decision": "Various points discussed", "rationale": "Based on conversation flow", "impact": "positive"}
                ],
                "action_items": [
                    {"action": "Continue conversation as needed", "priority": "medium", "timeline": "ongoing"}
                ],
                "insights": [
                    {"insight": "Productive conversation held", "significance": "Good communication", "application": "Apply learnings"}
                ],
                "summary_text": f"This conversation involved detailed discussion across multiple topics. The participants engaged in meaningful dialogue covering various aspects of the subject matter. Key points were discussed and insights were shared throughout the conversation.",
                "key_takeaways": [
                    "Productive conversation took place",
                    "Multiple topics were covered",
                    "Meaningful insights were shared"
                ]
            }

            result = {
                'success': True,
                'summary': fallback_summary,
                'platform': platform,
                'model': model_used,
                'conversation_length': len(conversation),
                'fallback': True
            }

            if credit_result.get('credits_used'):
                result['credits_used'] = credit_result['credits_used']
                result['credits_remaining'] = credit_result.get('remaining')

            return jsonify(result)

    except Exception as e:
        error_msg = str(e)
        error_type = type(e).__name__

        logging.error(f"=== Context summary error ===")
        logging.error(f"Error type: {error_type}")
        logging.error(f"Error message: {error_msg}")

        return jsonify({
            'success': False,
            'error': 'Failed to generate context summary',
            'details': error_msg[:200],
            'error_type': error_type
        }), 500

@app.route('/magic-pill-enhance', methods=['POST'])
def magic_pill_enhance():
    """Magic pill enhancement for single input text using practical magic principles"""
    try:
        # ADD CREDIT CHECK - 10 credits for magic pill
        credit_result = optional_credit_check('magic_pill_enhance')
        if not credit_result['success']:
            return jsonify({
                'error': credit_result['message'],
                'credits_required': 10  # Magic pill costs 10 credits
            }), 402

        data = request.get_json()
        input_text = data.get('text', '').strip()
        platform = data.get('platform', 'unknown')

        if not input_text:
            return jsonify({'error': 'Input text is required'}), 400

        print(f"ü™Ñ Magic pill enhancement for: {input_text[:50]}...")

        # Build magic pill enhancement prompt (adapted from synthesize-conversation)
        enhancement_prompt = f"""You are an expert prompt engineer creating "practical magic" - prompts that give users helpful details they wouldn't think of, without overwhelming them.

User's input text:
{input_text}

ANALYSIS FRAMEWORK:
1. What type of work is in progress? (writing, coding, planning, etc.)
2. What's the user's apparent skill level? (beginner asking for simple things vs advanced requests)
3. What practical improvements would genuinely help but they wouldn't think to ask for?

PRACTICAL MAGIC PRINCIPLES:
‚úÖ Add helpful specifics they wouldn't consider
‚úÖ Include real-world examples and use cases
‚úÖ Suggest common pitfalls to avoid
‚úÖ Add user-focused improvements that matter
‚úÖ Keep it practical and actionable
‚úÖ Create an OPTIMIZED PROMPT, not an answer
‚úÖ Refine their request to be more specific and effective
‚úÖ Help them ask better questions, don't provide solutions
‚ùå No overwhelming technical jargon
‚ùå No over-engineering or complex frameworks
‚ùå Don't change their core intent

EXAMPLES BY DOMAIN:

WRITING (Blog/Content):
‚ùå Basic: "Make the blog more engaging"
‚ùå Overwhelming: "Implement AIDA framework with conversion funnels and behavioral psychology"
‚úÖ Practical Magic: "Add personal anecdotes, include specific examples readers can relate to, address common objections people have about this topic, and end with actionable next steps"

CODING:
‚ùå Basic: "Add error handling to the component"
‚ùå Overwhelming: "Implement enterprise architecture with dependency injection and observer patterns"
‚úÖ Practical Magic: "Add helpful error messages users can understand, loading states so users know something's happening, and simple validation to prevent common mistakes"

CREATIVE (Poems/Stories):
‚ùå Basic: "Make the character description more detailed"
‚ùå Overwhelming: "Apply literary theory with metaphysical conceits and postmodern narrative techniques"
‚úÖ Practical Magic: "Add sensory details like sounds and textures, include emotional reactions that make readers connect with the character, and create a vivid setting that feels real"

BUSINESS:
‚ùå Basic: "Improve the marketing plan"
‚ùå Overwhelming: "Create omnichannel attribution models with predictive analytics and behavioral segmentation"
‚úÖ Practical Magic: "Include specific budget numbers, realistic timelines with milestones, ways to measure if it's working, and backup plans if the first approach doesn't work"

YOUR TASK:
Create ONE enhanced prompt that improves the user's basic request with practical details that create an "aha moment" - things that are genuinely helpful but the user wouldn't think to ask for. Give ONLY the enhanced prompt as output - don't ask questions - the prompt will be directly copy-pasted by the user.

Take their basic request and make it more detailed and effective while keeping the same intent. Refer to the Practical Magic examples for the appropriate length and depth.

Enhanced prompt:"""

        response = client.chat.completions.create(
            model="chatgpt-4o-latest",
            messages=[
                {
                    "role": "system",
                    "content": "You are an expert at creating 'practical magic' prompts - enhancements that give users helpful details they wouldn't think of, without overwhelming them. Focus on genuinely useful improvements that create 'aha moments'."
                },
                {
                    "role": "user",
                    "content": enhancement_prompt
                }
            ],
            temperature=0.3,
            max_tokens=800
        )

        enhanced_prompt = response.choices[0].message.content.strip()

        # Clean up the response - remove any meta text
        if enhanced_prompt.startswith("Enhanced prompt:"):
            enhanced_prompt = enhanced_prompt.replace("Enhanced prompt:", "").strip()
        if enhanced_prompt.startswith("Here's"):
            lines = enhanced_prompt.split('\n')
            enhanced_prompt = '\n'.join(lines[1:]).strip()

        result = {
            'success': True,
            'prompt': enhanced_prompt,
            'status': 'success',
            'platform': platform,
            'original_length': len(input_text),
            'enhanced_length': len(enhanced_prompt),
            'metadata': {
                'mode': 'magic_pill_enhance',
                'practical_magic': True
            }
        }

        if credit_result.get('credits_used'):
            result['credits_used'] = credit_result['credits_used']
            result['credits_remaining'] = credit_result.get('remaining')

        print(f"‚úÖ Magic pill enhancement complete")
        return jsonify(result)

    except Exception as e:
        print(f"‚ùå Magic pill enhancement error: {e}")
        return jsonify({
            'error': 'Failed to enhance prompt',
            'details': str(e)
        }), 500

if __name__ == '__main__':
    app.run(debug=True)

# Set application variable for PythonAnywhere
application = app
